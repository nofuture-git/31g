Notes Terraform
----

----
Terraform: Up & Running, 2nd Edition
by Yevgeniy Brikman
Publisher: O'Reilly Media, Inc.
Release Date: September 2019
ISBN: 9781492046905

code examples: https://github.com/brikis98/terraform-up-and-running-code
----

----
https://aws.amazon.com/getting-started/fundamentals-core-concepts/?e=gs2020&p=gsrc
----

----
Infrastructure as Code, 2nd Edition
by Kief Morris
Publisher: O'Reilly Media, Inc.
Release Date: December 2020
ISBN: 9781098114671
----

----
Terraform basics
 - is written in Go
 - performs API calls to a known cloud provider (AWS, Azure, 
   Google Cloud, DigitalOcean, OpenStack and more)
 - is a single .exe in Windows without any installer 
  - needs to be added to the PATH variable
 - uses environment variables for AWS IAM users
 [System.Environment]::SetEnvironmentVariable("AWS_ACCESS_KEY_ID", `
                                              "ABCDEFGHIJKLMNOPQRS", `
                                              [System.EnvironmentVariableTarget]::Process)
                                              
 [System.Environment]::SetEnvironmentVariable("AWS_SECRET_ACCESS_KEY", `
                                              "c3VwZXJfL1NlY3JldF9uZWVkc1RvQmUxMTExMTExMTE=", `
                                              [System.EnvironmentVariableTarget]::Process)
                                              
 - Terraform code is a syntax named HashiCorp Configuration Language (HCL)
 - is expected file extension of .tf
 - documentation at https://registry.terraform.io/providers/hashicorp/aws/latest/docs
 - terraform.exe will look for a file named 'main.tf' in the working directory
 - typical ignore files of Terraform are: .terraform *.tfstate *.tfstate.backup
----

----
Infrastructure as Code (IAC)
 - idea of how code is hosted, managed, deployed and monitored 
   is all considered a software problem is is handled as code
   itself
 - includes both the provision of elements and the config of said elements
 - benefits include:
  - self-service: by the developers without assistance from a sysadmin
  - speed: steps as code will run faster than any human user
  - safety: steps as code are not prone to typos and manual errors
  - documentation: the infrastructure is clearly defined in as code
    and not hindered by tribal knowledge
  - version control: infrastructure changes are under source control
    with logs, commit comments, user names, etc.
  - validation: IAC can be code reviewed
----

----
Principle Layers of Cloud Computing
 - first layer is the Infrastructure Platform:
 - second layer is Application Runtime Platform:
  - servers
  - container clusters
  - database clusters
 - third, top, layer is Applications Platform:
  - application packages
  - container instances
  - serverless code
----

----
Infrastructure as a Service
 - abbreviated as IaaS
 - at a minimum, it provides three principle services:
  - compute
  - storage
  - networking
 - often called Cloud Providers (e.g. AWS, Azure, etc.)
 - Platform as a Service (PaaS) is IaaS plus the 
   deployment pipelines, code-repo, automated tests, 
   project mgmt tools (e.g. KANBAN board), etc.
 - Function as a Service (FaaS) is serverless functions
 - Database as a Service (DBaaS) is for database's
----
 
----
Ad hoc scripts
 - IAC as bash, python, powershell scripts 
  - tends to lack a standard API for standard IAC tasks
  - quickly becomes overwhelming 
----

----
Configuration Management Tools 
 - IAC as applications to install and manage software on existing servers
 - examples include: Chef, Puppet, Ansible and SaltStack
 - is convention based for common IAC tasks like file 
   layout, secrets mgmt, etc 
 - idempotence: code that runs correctly no matter how many 
   times its run\re-run
 - intended for distributed networks of remote machines
----

----
Server Templating Tools
 - IAC as fully self-container snap-shots of a whole machine from OS up
 - examples include: Docker, Packer and Vagrant
 - developed the idea of immutable infrastructure 
  - don't change images, just make a whole new one
 - virtual machines and containers
  - a VM is virtualizing the very hardware 
  - container is virtualizing just the user space
   - user space being the part of virtual memory used by applications
   - in contrast to kernel space being the part of the virtual memory
     used by the kernel
----

----
Orchestration Tools
 - IAC as a configuration management tool of all the template servers
 - examples include: Kubernetes, Marathon/Mesos, Amazon Elastic Container 
   Service (Amazon ECS), Docker Swarm and Nomad
 - handle the updates to existing templates in a rolling fashion
  - blue-green deployment
  - canary deployment
 - auto-healing: idea of an orchestration tool replacing poor performing 
   running templates with new ones
 - auto-scaling: idea of an orchestration tool adding\removing running 
   templates based on demand-load
 - load-balancing: idea of orchestration tool distributing demand-load 
   efficiently across the running templates
 - service discovery: idea of orchestration tool allowing for running 
   templates to find and communicate with other running templates
----

----
Provisioning Tools
 - IAC as creation the infrastructure itself
 - examples include: Terraform, CloudFormation and OpenStack Heat
 - creates the servers, databases, caches, load balancers, queues, 
   monitoring, subnet cfg, firewall settings, routing rules, 
   digital certs, etc.
----

----
Common IaC Stacks
 - "stack" meaning everything needed to delivery the solution 
 
 - Stack Configuration Files
  - the variables are kept in independent files
  - one variable file per environment
  
 - Wrapper Stack
  - each environment is its own project 
  - shared code is imported as modules
  
 - Pipeline Stack Parameters
  - the variables are assigned within the pipeline
----

----
Terraform Resource Syntax
 - a first-class, kind-of, type is a 'resource'
 - looks similar to a CSS Rule
 resource "<PROVIDER>_<TYPE>" "<NAME>" {
  [CONFIG ...]
 }
 
 - syntax example:
 resource "aws_instance" "myExample" {
  ami = "ami-0c55b159cbfafe1f0"
  instance_type = "t2.micro"
 }
 
 - 'resource' is a keyword
 - "aws_instance" is a naming convention of provider_type
 - "myExample" is an identifier of this instance of this resource
 - what is within the body is specific config key-value pairs
   for that provider_type
----

----
Terraform Resource Attribute Reference
 - a string interpolation schema
 - a reference to some value defined elsewhere
 - uses a snake-and-dot notation
  - <PROVIDER_<TYPE> are same as always
  - <NAME> is the name of the resource 
  - <ATTRIBUTE> is some key-value in the body of 
    the resource
 <PROVIDER>_<TYPE>.<NAME>.<ATTRIBUTE>
 
 - assignment of some value to a reference 
   is accomplished by enclosing it in square-braces
  vpc_security_group_ids = [aws_security_group.instance.id]  
  
  - this would mean some other resource is defined 
    for the 'aws_security_group' 
  - the name of this resource is 'instance'
  - lastly, this resource has config attribute named 'id'
----   

----
Terraform Variable Assignment
 - three methods to assign variables
  - using 'someName.tfvars'
  - using environment variables which begin with 'TF_VAR_'
  - passing into the command line
   - this is given precedence over all other 
     forms of assignment
 terraform apply -var 'myvar=myvalue'
 
 - 'variables.tf' is for variable _declaration_
  - a default value is optional
 - 'somename.tfvars' is for variable assignment
  - assignment is based on root module
  - child modules that attempt to overwrite a value
    assigned in a root module will have _no_ affect
 - environment 'TF_VAR_' variables still need to be
   declared in the 'variables.tf' file 
----

----
Terraform Variables Declaration
 - variables may be eval'ed inside of string's within a .tf file 
   using PowerShell'esque string interpolation
  - use 'var' keyword, e.g. "app-${var.env}-something"
 - input variables use 'variable' keyword
 - output variables use 'output' keyword
 
 variable "my-port-number" {
  description = "Basic example of a programmatic terraform variable"
  type = number
  value = 8080
 }
 
 variable "my_list" {
  description = "A list example"
  type = list(number)
  default = [1,2,3]
 }
 
 variable "my_map" {
  description = "A map (aka assoc. array, hashtable, dictionary) example"
  type = map(string)
  
  default = {
    key1 = "value1"
    key2 = "value2"
    key3 = "value3"
  }
 }

 - here is a complex example where a type is being declared then 
   given a default value
 variable "my_object" {
  description = "An example of an object"
  type = object({
   name = string
   age = number
   tags = list(string)
   enabled = bool
  })
  
  default = {
   name = "value1"
   age = 15
   tags = ["a", "b", "c"]
   enabled = true
  }
 }
 
 - input variables can be referenced using special 'var' syntax within 
   a .tf file
 variable "my_other_variable" {
   description = "yet another way"
   type = number
   value = var.my-port-number
 } 
 
 - this allows for something to be printed after invoking terraform.exe
 output "something_out" {
  value = aws_instance.example.public_ip
  description = "Something useful here"  
 }
----

----
Terraform Local Variables
 - likewise variable declaration within a .tf file
 - the scope is limited to the module (i.e. the directory)
 - they can be referenced similar to input variables 
 - they are more concise and don't require a type

 #declaration and assignment of local variables
 locals {
   any_port = 0
   any_protocol = "-1"
   all_ips = ["0.0.0.0/0"]
 }
 
 resource "aws_security_group_rule" "allow_http_inbound" {
    type = "ingress"
    security_group_id = aws_security_group.alb.id
    
    #local variables referenced using keyword 'local'
    from_port = local.any_port
    to_port = local.any_port
    protocol = local.any_protocol
    cidr_blocks = local.all_ips
 }
----

----
Terraform Output Variables
 - allows for variables resolved within terraform's apply, 
   init, etc to be made as output
 - output variables receive a value through a terraform expression
 - an output variable can be queried 
   using 'terraform output my_output_variable'
 - module output variables can be resolved, within a .tf file,
   using 'module.my_module_dir_name.my_module_output_variable'
  - starts with keyword 'module' followed by the name of the module
    and then the name of the output variable
 
 #an output variable declaration
 output "my_output_variable" {
 
   #assigning the output variable a value with an expression
   value = aws_instance.example.public_ip
   description = "The public IP address of the the web server"
 }
 
 #outputs can also be declared on the module
 output "my_module_output_variable" {
   value = aws_autoscaling_group.example.name
   description = "Some name here"
 }
 
 #output values can be by-ref 
 output "my_enviro_output_variable" {
   value = module.my_module_dir_name.my_module_output_variable
   description = "Same as the last one"
 }
----

----
Provider Data
 - this is data defined by provider 
 - examples include Virtual Private Cloud data, subnet data, Amazon 
   Machine Image Ids, IP Address ranges, current user identity, etc.
 - similar syntax to 'resource'
 - body of rule typically defines the filtering used to find the data
 
 data "aws_vpc" "default" {
    default = true
 }
 
 data "aws_subnet_ids" "default" {
    vpc_id = data.aws_vpc.default.id
 }
 
 data "aws_iam_user" "example" {
    user_name = "noFuture.aws.app00"
 }
----

----
Terraform Builtin Functions
 - reference at https://www.terraform.io/docs/language/functions/index.html
 - variety of builtin functions within terraform
 - there are numeric, string, collection, encoding, file, date-time,
   crypto, network and conversion functions
----

----
Declaring a Terraform File as Data
 - example of a bash or PowerShell script file 

 data "template_file" "user_data" {
   template = file("my-script.sh")
   
   #declaring these here allows for string 
   # interpolation _inside_ the script file
   vars = {
   
     #using a combo of implicit and input variables
     server_port = var.server_port
     
     #these assume some data resource with 
     # outputs saved to terraform.tfstate
     db_address = data.terraform_remote_state.db.outputs.address
     db_port = data.terraform_remote_state.db.outputs.port
   }
 }
 
 - now within the content of 'my-script.sh', terraform 
   will perform string interpolation
  - not clear how this would work with PowerShell since
    it uses the same form of interpolation
 
 #!/bin/bash
 
 cat > index.html <<EOF
 <h1>Alive</h1>
 <p>DB address: ${db_address}</p>
 <p>DB port: ${db_port}</p>
 EOF
 
 nohup busybox httpd -f -p ${server_port} &
----

----
Terraform AWS Policy Actions
 - uses builtin terraform function 'jsonencode' which 
    transforms HCL into JSON
  - allows for less double-quotes and required commas 
 - AWS Policy Actions
  - uses a kind of fully qualified namespace property 
    to scope in on an action (e.g. iam, s3, ec2)
  - each AWS resource has its own set of applicable actions
  - the Actions follow a naming convention 
    of Verb-Noun (e.g. DeleteRole)
  - '*' can then be used as a wild-card op to include
    all verbs (e.g. Delete*) or all nouns (e.g. *Role*)
 
 #define a user for the load balancer
 resource "aws_iam_user" "lb" {
   name = "loadbalancer"
   path = "/system/"
 }
 
 #define the IAM policy
 resource "aws_iam_user_policy" "lb_ro" {
   name = "example"
   user = aws_iam_user.lb.name
   
   #'ec2:Describe*' means this policy allows 
   # within the Elastic Compute Cloud, Allow all 
   # actions, starting with the verb, "Describe"
   policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Action = [
         "ec2:Describe*"
        ]
        Effect = "Allow"
        Resource = "*"
      },
    ]
   })
 }
----

----
Terraform Path Variable
 - are a kind of global variable relating to the path
 - common uses:
  - path.module: the path of the module in which this expression 
                 appears
  - path.root:   the path to the root module
  - path.cwd:    the path to the current working directory
  
 - use looks like: 
  template = file("${path.module}/something.ps1")
----

----
Terraform Modules
 - for reusable units of .tf code
 - the general unit is a whole directory with .tf files therein
 - the name of the directory must match the name appearing after
   'module' 
  - it appears, that '-' is, in the dir name, replaced with '_' 
    in the resource name
 
 provider "aws" {
   region = "us-east-2"
 }
 
 #this would be a directory named 'webserver-cluster'
 module "webserver_cluster" {
 
   #again, directory name matches module name
   #could be an URL 'github.com/myRepo/modules/webserver-cluster'
   source = "../modules/webserver-cluster"
   
   #'cluster_name' would be a in the 'variables.tf' 
   #  of the 'webserver-cluster' directory, but it
   #  would not be assigned any value with 'default'
   #'cluster_name' would also be in the 'variables.tf'
   #  of _this_ working directory and here it _would_
   #  have a 'default' value
   cluster_name = var.cluster_name
 }
----

----
Terraform 'count' Language Construct
 - a meta-parameter present on every resource declaration
  - does not work _within_ an inline block
 - indicates the number of copies to make of a resource
 - using 'count' in a resource declaration still results
   in _one_ resource, that _one_ resource is an array 
 - an array resource must be accessed by ordinal
  
 resource "aws_iam_user" "example" {
 
   #specify three copies
   count = 3
   
   #use string interpolation in the naming convention
   name = "iam_user_${count.index}"
 }
 
 - 'count' can also be used to access array's by ordinal
 
 #would define the names-array 
 variable "iam_user_names" {
   description = "The names of Identity and Access Management (IAM) users"
   type = list(string)
   default = ["abraham", "issac", "jacob"]
 }
 
 resource "aws_iam_user" "another_example" {
   
   #the reference the variable 
   count = length(var.iam_user_names)
   
   #here the iteration is tied back to the length
   # of the variable
   name = var.iam_user_names[count.index]
 }
 
 - to access an array-of-resources, ordinal is the 
   only workable identifier
 output "user_0_arn" {
 
  #to access a specific item in the array
  #  can use '[*]' to apply to all items in the array
  value = aws_iam_user.another_example[0].arn
  description = "The ARN of the first IAM user"
 }
----

----
Terraform Resources 'for_each' Language Construct 
 - creates new resources not an array of resources
 - allows for iteration over lists, sets, or hashtables
 - can make multiple copies of an entire resource
 
 variable "my_names" {
   description = "My Names"
   type = list(string)
   default = ["Caesar", "Pompey", "Crassus"]
 }
 
 resource "aws_iam_user" "my_imperators" {
   
   #reference the variable boxed in a function
   for_each = toset(var.my_names)
   
   #access the iteration value 
   name = each.value
 }
 
 #to access resources created in the for_each
 output "all_arns" {
 
   #box the reference in another builtin 'values' function
   value = values(aws_iam_user.my_imperators)[*].arn
 }
----

----
Terraform Inline 'for' Expression
 - an inline loop expression
 
 variable "my_names" {
   description = "My Names"
   type = map(string)
   default = {
    Pompey = "the good"
    Caesar = "the bad"
    Crassus = "the ugly"
   }
 }
 
 output "my_names" {
 
   #where 'k,v' is ref to the current iteration as a tuple
   value = [for k,v in var.my_names : upper(k)]  
 }
----

----
Terraform Conditional with 'count'
 - when meta-parameter 'count' is '0' 
   (zero), no resource gets made 
 - add this to tertiary inline op to get
   conditional creation of resources
   
 #define some input variable to toggle
 variable "enable_my_feature" {
   description = "Used to enable some feature"
   type = bool
 }

 resource "aws_autoscaling_schedule" "scale_off_hours" {
 
   #when bool is false, count is 0 so nothing is created
   count = var.enable_my_feature ? 1 : 0
   
   #rest of resource config here
 }
----

----
Running terraform
 - working directory contains a main.tf file
 - run to download dependencies on given provider 
  - as defined in the main.tf 'provider'
  - will also create various other files and folder in working dir
  - is idempotent so can run whenever
 terraform init
 
 - next is the command 'plan'
  - like a 'WhatIf' parameter in PowerShell
  - determines what terraform _will_ do
  - handles the implicit dependencies so resources can be
    declared in .tf files in any order
  - console output has three ascii chars to indicate
    expected future state
   - '+' means something will be created
   - '-' means something will be removed
   - '~' means something will be modified
   - '-/+' means something will be replaced
 terraform plan -var "my_magic_number=90"
 
 - 'apply' command will push what was planned to the 
   cloud provider
  - within the cloud providers console verify it worked
 terraform apply
 
 - 'output' command can be used to query some value of 
   a defined output variable
 terraform output something_out
 
 - 'destroy' command will remove whatever apply created
 terraform destroy
----

----
Basic AWS Elastic Compute Cloud (EC2) instance example

# port 8080 because any port less than 1024 requires root user privs.
variable "my_server_port" {
    description = "The port used in this example"
    type = number
    default = 8080
}

#define the aws instance of a full web server
resource "aws_instance" "example" {
    
    #this is the Id for Ubuntu 18.04 Amazon Machine Image (AMI)
    ami = "ami-0c55b159cbfafe1f0"
    
    #1 virtual CPU and 1 GB of memory
    instance_type = "t2.micro"
    
    #need to attach a security policy (defined below) to this instance
    # VPC stands for Virtual Private Cloud
    vpc_security_group_ids = [aws_security_group.instance.id]
    
    #a Bash script to act as the web content and server
    # uses terraform's string interpolation to assign the port
    user_data = <<-EOF
              #!/bin/bash
              echo "Alive" > index.html
              nohup busybox httpd -f -p ${var.my_server_port} &
              EOF
    
    #this name will appear in my AWS Console's EC2's Instances list
    tags = {
        Name = "terraform-example"
    }
}

#AWS does not allow in nor out traffic by default
# a security setting is needed and then attached to port 8080
resource "aws_security_group" "instance" {
    name = "terraform-example-instance"
    
    #ingress for traffic coming in (as opposed to egress - traffic going out)
    ingress {
    
        #using a variable reference to assign the port
        from_port = var.my_server_port
        to_port = var.my_server_port
        protocol = "tcp"
        
        #Classless Inter Domain Routing (CIDR) 
        cidr_blocks = ["0.0.0.0/0"]#on any IP
    }
}

#this will print the IP after invoking the 'apply' command
output "public_ip" {

    #NOTE: 'example' is the name _we_ gave the resource above
    value = aws_instance.example.public_ip
    description = "The public IP address of the web server"
}
----

----
Creating an AWS EC2 cluster 
 - involves the idea of launch configuration
 - and the idea of auto-scaling group (ASG)
 - an the idea of a load balancer
  - Application Load Balancer: for HTTP, HTTPS traffic
  - Network Load Balancer: for TCP, UDP and TLS traffic
  - load balancers work as:
    Request -> Listeners -> Listener Rules -> Target Groups

provider "aws" {
  region = "us-east-2"
}

#variable declaration
variable "server_port" {
    description = "The port used in this example"
    type = number
    default = 8080
}
#the part that is copied and distributed to each 
# item in the cluster
resource "aws_launch_configuration" "example" {

  #this was called 'ami' in the 'aws_instance'   
  image_id        = "ami-0c55b159cbfafe1f0"
  instance_type   = "t2.micro"

  #this was called 'vpc_security_group_ids' in 'aws_instance' 
  security_groups = [aws_security_group.instance.id]

  user_data = <<-EOF
              #!/bin/bash
              echo "Hello, World" > index.html
              nohup busybox httpd -f -p ${var.server_port} &
              EOF

  #given immutable nature, first create new, then delete old
  lifecycle {
    create_before_destroy = true
  }
}

#define the actual group with its upper and lower limits
resource "aws_autoscaling_group" "example" {

  #use an implicit reference (again, 'example' was what we named it)
  launch_configuration = aws_launch_configuration.example.name

  #subnet ids, distributes the group across various availability zones
  # so that if a data-center goes down the others are still up
  vpc_zone_identifier  = data.aws_subnet_ids.default.ids

  #the load balancer's target group
  target_group_arns = [aws_lb_target_group.asg.arn]

  #this overrides the default health check of "EC2"
  # "ELB" is better since it uses the target group's health check
  health_check_type = "ELB"

  min_size = 2
  max_size = 10

  tag {
    key                 = "Name"
    value               = "terraform-asg-example"
    propagate_at_launch = true
  }
}

#the security group for the launch configuration
resource "aws_security_group" "instance" {
  name = "my-security-group-A"

  ingress {
    from_port   = var.server_port
    to_port     = var.server_port
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }
}

#boilerplate code for subnet ids
data "aws_vpc" "default" {
  default = true
}

#more boilerplate code for subnet ids
data "aws_subnet_ids" "default" {
  vpc_id = data.aws_vpc.default.id
}

#define the load balancer itself
resource "aws_lb" "example" {

  name               = "my-lb"

  load_balancer_type = "application"

  #continuation of AWS EC2 cluster examples above
  subnets            = data.aws_subnet_ids.default.ids

  #defined below, required to allow traffic
  security_groups    = [aws_security_group.alb.id]
}

#define the listener for the load balancer
resource "aws_lb_listener" "http" {

  #this implicit reference to the resource defined above
  load_balancer_arn = aws_lb.example.arn
  port              = 80
  protocol          = "HTTP"

  #by default return 404
  default_action {
    type = "fixed-response"

    fixed_response {
      content_type = "text/plain"
      message_body = "404: page not found"
      status_code  = 404
    }
  }
}

#define the target group for the load balancer
resource "aws_lb_target_group" "asg" {

  name = "my-lb-target-group"

  port     = var.server_port
  protocol = "HTTP"
  vpc_id   = data.aws_vpc.default.id

  #used to check each member of the ASG
  health_check {
    path                = "/"
    protocol            = "HTTP"
    matcher             = "200"
    interval            = 15
    timeout             = 3
    healthy_threshold   = 2
    unhealthy_threshold = 2
  }
}

#define the listener rule for the load balancer
resource "aws_lb_listener_rule" "asg" {

  #"http" is the name given to our aws_lb_listener above
  listener_arn = aws_lb_listener.http.arn
  priority     = 100

  condition {
    path_pattern {
      values = ["*"]
    }
  }

  action {
    type             = "forward"
    #another implicit reference 
    target_group_arn = aws_lb_target_group.asg.arn
  }
}

#security for the load balancer itself, previous security group was for
#each item in the cluster
resource "aws_security_group" "alb" {

  name = "my-security-group-B"

  # Allow inbound HTTP requests
  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  # Allow all outbound requests
  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
}

#need to print the output DNS name
output "alb_dns_name" {
   value = aws_lb.example.dns_name
   description = "The domain name of the load balancer"
}
----

----
Terraform State management
 - each run of Terraform records its state in a file 
   named 'terraform.tfstate'
 - this state file is known as 'backend'
 - .tfstate file is JSON
 - output of the 'plan' command is the diff of .tf files
   and actual state on cloud provider
 - two kinds of backend
  - Local Backend
   - the default of saving .tfstate file to working directory
   - doesn't work for a team-setting
  - Remote Backend
   - these are within the cloud providers
   - examples include: Azure Storage, Google Cloud Storage, 
     Amazon Simple Storage Service (S3), etc.
----

----
Setting up Remote Backend with Amazon S3
 - this should be performed in clean directory 
   with no prior .tfstate files
 - a call to 'terraform init' is required to download
   the dependencies

#specify the provider 
provider "aws" {
  region = "us-east-2"
}

#specify the remote storage place
resource "aws_s3_bucket" "terraform_state" {
  
  #this is globally unique name for _all_ AWS
  bucket = "nofuture-aws-s3-terraform-bucket"
  
  #this is a kind-of lock, invoking 'terraform destroy' 
  # will error out
  lifecycle {
    prevent_destroy = true
  }
  
  #this needs to be enabled so that the remote backend 
  # .tfstate files are versioned
  versioning {
    enabled = true
  }
  
  #enable server-side encryption 
  # this means the file is encrypted on the remote drive
  server_side_encryption_configuration {
    rule {
      apply_server_side_encryption_by_default {
        sse_algorithm = "AES256"
      }
    }
  }
}

#specify the manner of remote storage file locking
resource "aws_dynamodb_table" "terraform_locks" {
  name = "nofuture-aws-dynamodb-terraform-locks"
  billing_mode = "PAY_PER_REQUEST"
  
  #this hash key value must match this (case-sensitive)
  hash_key = "LockID"
  
  #every 'hash_key' must also be defined as an attribute
  #type is 'S' for string, 'N' for number and 'B' for binary
  attribute {
    name = "LockID"
    type = "S"
  }
}
----

----
Configure Terraform to Store State in S3 Bucket
 - this must be run after the previous 
   section (i.e. 'Setting up Remote Backend with Amazon S3')
   has already been applied
 - previous step was to create resources needed for 
   Remote Backend 
 - this step is configuring terraform to use the Remote Backend

#specify the provider 
provider "aws" {
  region = "us-east-2"
}  

#need to config terraform to use Remote Backend 
# NOTE: no variables can be used here
terraform {
  backend "s3" {
    
    #implicit reference to the S3 bucket defined above
    bucket = "nofuture-aws-s3-terraform-bucket"
    
    #file path within the S3 bucket
    key = "global/s3/terraform.tfstate"
  
    #also needs to match the S3 bucket defined above
    region = "us-east-2"
    
    #implicit reference to the dynamodb table defined above
    dynamodb_table = "nofuture-aws-dynamodb-terraform-locks"
    
    #this is a second layer of encryption, .tfstate file 
    # is encrypted, in addition to the S3 bucket being encrypted
    encrypt = true
  }
}
----