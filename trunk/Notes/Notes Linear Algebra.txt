Notes Linear Algebra

----
Practical Linear Algebra, 3rd Edition
By: Gerald Farin; Dianne Hansford
Publisher: CRC Press
Pub. Date: August 19, 2013
Web ISBN-13: 978-1-4822-1128-3
Web ISBN-13: 978-1-4665-7959-0
Print ISBN-10: 1-4665-7956-0
Web ISBN-10: 1-4665-7959-5
Print ISBN-13: 978-1-4665-7956-9
Web ISBN-10: 1-4822-1128-9
Web ISBN-13: 978-1-4665-7958-3
Pages in Print Edition: 514
----

----
Linear Algebra: Theory and Applications, 2nd Edition
By: Cheney
Publisher: Jones & Bartlett Learning
Pub. Date: December 29, 2010
Web ISBN-13: 978-1-4496-1353-2
Print ISBN-13: 978-1-4496-1352-5
Pages in Print Edition: 624
----

----
Practical Graph Mining with R:
By: Nagiza Samatova; William Hendrix; John Jenkins; Kanchana Padmanabhan; Arpan Chakraborty
Publisher: Chapman and Hall/CRC
Pub. Date: July 15, 2013
Print ISBN-13: 978-1-4398-6084-7
Pages in Print Edition: 495
----

----
https://www.math.uh.edu/~jmorgan/Math6397/day13/LinearAlgebraR-Handout.pdf
----

----
R in Action, Second Edition
Data analysis and graphics with R
Robert I. Kabacoff
May 2015 ISBN 9781617291388 608 pages printed in black & white
----

----
Regression Analysis with R
By: Giuseppe Ciaburro
Publisher: Packt Publishing
Pub. Date: January 31, 2018
Print ISBN-13: 978-1-78862-730-6
Web ISBN-13: 978-1-78862-270-7
Pages in Print Edition: 422
----

----
https://www.ncbi.nlm.nih.gov/books/NBK253312/
----

----
Linear Algebra A Geometric Approach 2nd ed.
Theodore Shifrin, Malcom R. Adams
ISBN-13: 978-1-4292-1521-3
ISBN-10: 1-4292-1521-6
2011, 2002 by W. H. Freeman and Company
----

----
R Summary
 - is a GNU port of the "S" language where S was a stat lang
   developed at Bell Labs by John Chambers.
 - is open-source, dev'ed by Robert Gentlement and Ross Ihaka
 
 -package management
  - get more libs at https://cran.r-project.org/web/packages/available_packages_by_name.html
  - take the zip (window) and unzip to R install dir named \library
  - load using 
  library(sna)
 
 - test the version at runtime
  R.Version()
  
 - package version
  packageVersion("packageName")
  
 - package mangement
  - worked within VS 2017 R Interactive
  install.packages("packageName", lib="C:/Program Files/Microsoft/R Client/R_SERVER/library", dependencies = TRUE)
----

----
R Ops
 - Assignment
  <- assignment at environment 
  =  only for the "top-level" (i.e. command prompt)
  -> assignment in reverse where variable is right operand
  <<- assignment is global
 
 - Logical 
  TRUE 
  or just 'T'
  FALSE
  or just 'F'
  < 	less than
  <=  	less than or equal to
  > 	greater than
  >=	greater than or equal to
  ==	exactly equal to
  !=	not equal to
  !x	Not x
  x | y	x OR y
  x & y	x AND y 
  isTRUE(x)	test if X is TRUE
  isTRUE(2 > 1 | 1/0) #is short-circuit logical ops
  
 -Mathematical Ops
  +, -, *, /  (arithmatic)
  ** or ^     (exponent) 
  %%          (modulus)
  %*%         (matrix multiplication)
  ~           (a kind of R specific thing, see help)
  
 -Flow Control Ops
  if(TRUE) x <- 1 else x <- 2 #inline if
  for(i in c(1:10)) print(i)
  a <- 0; while(a < 10) a <- a+1
  apply(x,(1|2),cos) #where, x is a matrix
                   # 1 is for each row, 2 for each column
                   # cos is the builtin f(x) cosine
  lapply(x,cos) #apply cosine builtin to every element
 
 - Casting
  as.data.frame(x)
  as.matrix(x)
  as.vector(x)
  as.list(x)
----

----
R Builtins
 #define a vector
 a <- c(1,3,2)
 b <- c(2,8,9)
 bb <- seq(start,end[,step]) #gen' stepped sequences 
 cc <- c(1:10) gen' single sequence
 dd <- b[!b %in% 9] #a kind of selector to get the vector less this item
 
 #assignment can work both ways
 c(1,3,2) -> a  
 c(2,8,9) -> b
 
 #multiple statement on single line are ; sep'ed
 c(1,3,2) -> a; b <- c(2,8,9)
 
 #vector index op
 a <- c(1,2,3)
 a[1] 
 a[-2] #means everything except index 2
 
 #transpose 
 t(a)
 
 #scalar multiplication
 7*a
 
 #sum of vectors
 a+b
 
 #inner product
 sum(a*b)
 
 #vector length (e.g |a|)
 sqrt(sum(a*a))
 
 #repeat 0,1 vector
 rep(0,5)
 rep(1,5)
 
 #orthogonal vector have inner product of zero
 v = c(0,5)
 w = c(3,0)
 sum(v*w)  #equals zero
 
 #define a matrix
 #df are read column-by-column 
 A <- matrix(c(1,3,2,2,8,9), ncol = 3)
 #set to read row-by-row
 B <- matrix(c(5, 8, 3, 4, 2, 7), ncol = 3, byrow = T)
 
 #matrix index op
 A[1] #same as A[1,1] 
 A[1,] #row 1
 A[,1] #column 1
 
 #scalar multiplication
 7*A
 
 #transpose matrix
 t(A)
 
 #matrix addition
 A + B
 
 #column-vector multiplication
 b <- c(5,8)
 A %*% a
 
 #matrix multiplication
 #A as r X c and B as c X t, AB is r X t matrix
 A <- matrix(c(1,3,2,2,8,9), ncol=2)
 B <- matrix(c(5,8,4,2), ncol = 2)
 A %*% B
 
 #identity matrix
 diag(1,3)
 
 #find inverse
 A <- matrix(c(1,3,2,4), ncol=2, byrow=T)
 B <- solve(A)
 A %*% B       #identity matrix
 
 #find determinent
 A <- matrix(c(1,0,5,1), ncol=2)
 B <- det(A)
 
 #find eigen values, vectors
 # - the result is a type with two props
 # - ev$val for eigen values
 # - ev$vec for eigen vectors
 ev <- eigen(A)
 
 #pivot data
 # ColumnA  ColumnB  ColumnC
 # labelA     0        11
 # labelB     0        55
 # labelA     0        15
 # labelB     0        34
 # ...
 # --into--
 # labelA  labelB
 # 11      55
 # 15      34
 # ...
 MyData <- matrix(c("labelA","labelB","labelA","labelB",0,0,0,0, 11,55,15,34), ncol = 3)
 MyPivot <- matrix(MyData[,3], ncol=2, byrow=TRUE, dimnames=list(NULL, c("labelA", "labelB")))
  
 #IO
 myData <- read.table("C:/MyR/MyRData/MyData.tsv",header=TRUE)
 sink("C:/MyR/MyOutput/output.txt") #will route all output to file
 sink() #sets output back to console.
 MyCsvData=read.csv ("C://SomeFolder//SomeFile.csv", header=TRUE, sep=";")
 plot(MyCsvData$SomeColumn,MyCsvData$SomeOtherColumn)
 
 #requires the package readxl
 SomeMsExcelData <- read_excel("MyExcel.xlsx")
 
 #set the working directory
 setwd("C://Projects")
 
 #namespace conflicts can be handled using full qualified 
 sgd::sgd
 
 #the R install will come with some canned data 
 library(help="datasets")
 
 #user defined function (in-line)
 myNormalForm <- function(x1, x2) -2*x1 + 4*x2 - 4
 
 #user defined function(multi-line)
 # - written in a separate UTF8 file
 # - then imported into console 
 #  - using 'source("path-to-file")'
 #  - path-separator is unix-style /
 
 vLen <- function(a) {
    #check for null args
    if(missing(a)) a = 1
    sqrt(sum(a*a))
 }
 source("C:/MyR/UserFunctions/LinearAlgebra.r")
 vLen(c(5,4)) #6.403124
 
 #apply and custom function
 # the '3' indicates which attribute in 'someData'
 odds.ratio = function(x){
   (x[1,1]*x[2,2])/(x[1,2]*x[2,1])
 }
 MyOdds <- apply(someData, 3, odds.ratio)
 
 #other usefull builtin
 ls()  # display all the variables defined so far in the console.
 rm(a) # gc a variable 
 er<-runif(10,min=-1,max=1) #get 10 random values between -1 and1

 help("[[") #gets help on builtin symbols (displays in browser)
 View(data) #dislplays it like a spread sheet
 
 # Numeric builtins
 length(a); mean(a); min(a); max(a); var(a)
 abs(x); sqrt(x); ceiling(x); floor(x)
 trunc(x); round(x[, n]); signif(x[, n])
 cos(x); sin(x); tan(x); #use radians not degees
 log(x); log10(x); log2(x)
     
 #Stat builtins
 cov(SomeData$FieldOne, SomeData$FieldTwo) #covariance
 cor(SomeData$FieldOne, SomeData$FieldTwo) #correlation coefficient
 sd(SomeData$FieldOne) #standard dev
 
 #dynamic types
 myDyn <- list(name="myType", someProp=11, anotherProp=c(1:10))
 #access props with '$' instead of c-style dot
 myDyn$name
 #can also use an index
 myDyn[1]
 
 #data frames are dynamic runtime tables
 a <- c(1, 2, 3)
 b <- matrix(c(4:15), nrow=3, ncol=4)
 p <- c("R","is","easy")
 df <- data.frame(a,b,p)
 
 #get runtime type info
 str(someDataFrame)

 #top 10 of a data frame
 head(someDataFrame)

 #get stat data per column
 summary(someDataFrame)
 
 #object property reflection
 names(SomeObjectInstance)
  
 #dataframe with property-style names
 prop00 <- 11.0
 prop01 <- TRUE
 prop02 <- "a string"
 myDf <- data.frame(prop00, prop01, prop02)
 
 #dataframe indexing
 myDf[1]       #would get first column, all rows
 myDf[1,]      #get the first row, all columns
 myDf[,1]      #get the first column, all rows, as single array
 myDf[1:5,]    #get first 5 rows, all columns
 myDf[,1:2]    #get first 2 columns, all rows
 myDf[1:2]     #same as the last
 myDf[1:5,1:2] #get first 5 rows first 2 columns
 
 #data -> table -> data-frame
 myMatrix <- matrix(c(362,160,8,64), nrow=2)
 colnames(myMatrix) <- c("ColumnA", "ColumnB")
 rownames(myMatrix) <- c("Row1", "Row2")
 myTable <- as.table (myMatrix)
 myDataframe <- as.data.frame(myMatrix)
 
 #list to vector - does not behave the same as as.vector
 unlist(lapply(someDataFrame, function(x) which(is.na(x))))
----

----
My R Functions
 library(ggplot2)
 # used throughtout these notes
 # placed together here to allow for cut\paste in CLI
 
 getMy.Convert.Radians2Degrees <- function(a) a * 180/pi
 getMy.Convert.Degrees2Radians <- function(a) (a / 1) * (pi / 180)
 
 getMy.Draw.CoordGraph <- function(min, max){
     myX <- seq(min,max)
     myY <- seq(min,max)
     mydataframe <- data.frame(myX, myY)
     
     #setting shape makes it a blank coord-plane (will print a warning msg, just ignore)
     myplot <- ggplot(mydataframe, aes(x = myX, y = myY)) + geom_point(shape=NA)
     
     #add the "0" to the lower-left 
     myplot <- myplot + annotate("text", x=-0.20, y=-0.5, label="0")
     
     #draw the x and y axis 
     myplot <- myplot + geom_vline(xintercept = 0)
     myplot <- myplot + geom_hline(yintercept = 0)
     return(myplot)
 }
 
 getMy.Draw.Point <- function(coordPlot, p, ptColor = "black", pointLabel = ""){
    xCoord <- p[1]
    yCoord <- p[2]
    
    d <- data.frame(x = xCoord, y = yCoord, ptColor = ptColor)
    coordPlot <- coordPlot + geom_point(aes(x,y), data = d, colour=ptColor)
    if(pointLabel == "") pointLabel = sprintf("(%s,%s)",xCoord, yCoord)
    coordPlot <- coordPlot + annotate("text", x=xCoord-0.43, y=yCoord-0.43, label=pointLabel)
    return(coordPlot)
 }
 
 getMy.Draw.Vector.NonOrigin <- function(coordPlot, myOrign, myVector, lnColor = "black", vectorLabel = "") {
     xCoord <- myVector[1]
     yCoord <- myVector[2]
     xOrigin <- myOrign[1]
     yOrigin <- myOrign[2]
     d <- data.frame(x1 = xOrigin, y1 = yOrigin, x2 = xCoord, y2 = yCoord, lnColor = lnColor)
     myStdArrow <- arrow(length = unit(0.03, "npc"))
     coordPlot <- coordPlot + geom_segment(aes(x = x1, y = y1, xend = x2, yend = y2), 
         data = d, arrow = myStdArrow, size = 1, colour=lnColor)
     if(vectorLabel == "") vectorLabel = sprintf("(%s,%s)",xCoord, yCoord)
     coordPlot <- coordPlot + annotate("text", x=xCoord-0.43, y=yCoord-0.43, label=vectorLabel)
     return(coordPlot)
 }
 
 getMy.Draw.Vector <- function(coordPlot, myVector, lnColor = "black", vectorLabel = "") {
     coordPlot <- getMy.Draw.Vector.NonOrigin(coordPlot, c(0,0), myVector, lnColor, vectorLabel)
     return(coordPlot)
 }
 
 getMy.Draw.Segment <- function(coordPlot, startVector, endVector, lnColor="plum"){
     xStart = startVector[1]
     yStart = startVector[2]
     xEnd = endVector[1]
     yEnd = endVector[2]
     d <- data.frame(x1 = xStart, y1 = yStart, x2 = xEnd, y2 = yEnd, lnColor = lnColor)
     coordPlot <- coordPlot + geom_segment(aes(x = x1, y = y1, xend = x2, yend = y2), 
         data = d, size = 1, colour=lnColor, linetype="dashed")
     return(coordPlot)
 }
 
 getMy.Draw.Angle <- function(coordPlot, a1, a2, lnColor="#3A75FF"){
     a1Percent <- a1 * 0.2
     a2Percent <- a2 * 0.2
     x1 <- a1Percent[1]
     y1 <- a1Percent[2]
     x2 <- a2Percent[1]
     y2 <- a2Percent[2]
     d <- data.frame(x1, y1, x2, y2, lnColor = lnColor)
     coordPlot <- coordPlot + geom_curve(aes(x = x1, y = y1, xend = x2, yend = y2), 
         data = d, colour=lnColor)
     a1PlusA2 = ((a1+a2) * 0.5) * 0.25
     angle = getMy.Vector.Angle(a1,a2)
     coordPlot <- coordPlot + annotate("text", x=a1PlusA2[1], y=a1PlusA2[2], label=sprintf("%s°",round(angle,1)))
     return(coordPlot)
 }
 
 getMy.Draw.Line <- function(coordPlot, xPoints, yPoints, lnColor="black"){
     d <- data.frame(x = xPoints, y = yPoints)
     coordPlot <- coordPlot + geom_path(mapping = aes(x, y), data = d, 
        colour=lnColor, arrow = arrow(ends="both"))
     return(coordPlot)
 }
 
 getMy.Draw.Triangle <- function(mycoord, a1, a2, a3, fillColor = "lightblue"){
   d <- data.frame(x=c(a1[1],a2[1],a3[1]), y=c(a1[2],a2[2],a3[2]), t=c("a","a","a"))
   mycoord <- mycoord + geom_polygon(data = d, mapping = aes(x = x, y = y, group = t), fill = fillColor)
   return(mycoord)
 }
 
 getMy.Vector.EuclideanNorm <- function(v){
     sqrt(v[1]^2 + v[2]^2)
 }
  
 getMy.Vector.Normalized <- function(v){
     v / getMy.Vector.EuclideanNorm(v)
 }
 getMy.Vector.Distance <- function(q,p){
     getMy.Vector.EuclideanNorm(q-p)
 }
 
 getMy.Vector.CosTheta <- function(a,b){
     (a %*% b) / (getMy.Vector.EuclideanNorm(a) %*% getMy.Vector.EuclideanNorm(b))
 }
 
 getMy.Vector.Angle <- function(u, v){
     myCosTheta <- getMy.Vector.CosTheta(u,v)
     myAcosRadians <- acos(myCosTheta)
     #R is in radians
     myDegrees <- myAcosRadians * (180 / pi)
     return(myDegrees)
 }
 
 getMy.Vector.OrthoProj <- function(v,w){
     ((v %*% w)/getMy.Vector.EuclideanNorm(v)^2) * v
 }
 
 getMy.Line.Implicit.Coeffs.FromVectors <- function(p,q){
     v <- q - p
     ab <- t(c(-1*v[2], v[1]))
     a <- ab[1,1]
     b <- ab[1,2]
     c <- -1 * a * p[1] - b * p[2]
     return(data.frame(a,b,c))
 }
  
 getMy.Line.Explicit.Coeffs.FromVectors <- function(p,q){
     myImpVars <- getMy.Line.Implicit.Coeffs.FromVectors(p,q)
     a <- myImpVars$a
     b <- myImpVars$b
     c <- myImpVars$c
     myCoeffs <- getMy.Line.Explicit.Coeffs.FromImplicit(a,b,c)
     return(myCoeffs)
 }
  
 getMy.Line.Explicit.Coeffs.FromImplicit <- function(a,b,c){
     aTilde <- (-1 * a)/b
     bTilde <- (-1 * c)/b
     return(data.frame(slope=aTilde, intercept=bTilde))
 }
  
 getMy.Line.Reciprocal.Explicit.Coeffs.FromImplicit <- function(a,b,c,r){
     myCoeffs = getMy.Line.Explicit.Coeffs.FromImplicit(a,b,c)
     slope <- myCoeffs$slope
     intercept <-myCoeffs$intercept
     recipCoeffs <- getMy.Line.Reciprocal.Explicit.Coeffs.FromExplicit(slope, intercept,r)
     return(recipCoeffs) 
 }
 
 getMy.Line.Reciprocal.Explicit.Coeffs.FromVectors <- function(p,q,r){
     myCoeffs = getMy.Line.Explicit.Coeffs.FromVectors(p,q)
     slope <- myCoeffs$slope
     intercept <-myCoeffs$intercept
    
     #get the perpendicular line 
     recipCoeffs <- getMy.Line.Reciprocal.Explicit.Coeffs.FromExplicit(slope, intercept, r)
     return(recipCoeffs)
 } 
 
 getMy.Line.Reciprocal.Explicit.Coeffs.FromExplicit <- function(slope, intercept, r){
     recipSlope <- -1*(1/slope)
     recipIntercept <- r[2]-recipSlope*r[1]
     return(data.frame(slope=recipSlope, intercept=recipIntercept))
 }
  
 getMy.Line.Explicit.Fx.FromImplicit <- function(a,b,c){
     myCoeffs <- getMy.Line.Explicit.Coeffs.FromImplicit(a,b,c)
     myExpLn <- function(x) myCoeffs$slope*x + myCoeffs$intercept
     return(myExpLn)
 }
  
 getMy.Line.Explicit.Fx.FromVectors <- function(p,q){
     myImpVars <- getMy.Line.Implicit.Coeffs.FromVectors(p,q)
     a <- myImpVars$a
     b <- myImpVars$b
     c <- myImpVars$c
     myExpLn <- getMy.Line.Explicit.Fx.FromImplicit(a,b,c)
     return(myExpLn)
 }

 getMy.Line.Distance.Point.FromVectors <- function(p,q,r){
     #get implicit vars
     myImpVars <- getMy.Line.Implicit.Coeffs.FromVectors(p, q)
     a <- myImpVars$a
     b <- myImpVars$b
     c <- myImpVars$c
     d <- getMy.Line.Distance.Point.FromImplicit(a,b,c,r)
     return(d)
 }
 
 getMy.Line.Distance.Point.FromImplicit <- function(a,b,c,r){
     d <- abs(a*r[1] + b*r[2] + c) / sqrt(a^2 + b^2)
     return(d)
 }
 
 getMy.Line.Closest.Point.FromVectors <- function(p, v, r){
     #want to express as explicit fx 
     myCoeffs = getMy.Line.Explicit.Coeffs.FromVectors(p,v)
    
     #get the line coeffs
     slope <- myCoeffs$slope
     intercept <-myCoeffs$intercept
     closetPt <- getMy.Line.Closest.Point.FromExplict(slope, intercept, r)
     return(closetPt)
 }

 #https://www.youtube.com/watch?v=YbHOzJIHS1k
 getMy.Line.Closest.Point.FromExplict <- function(slope, intercept, r){
     recipCoeffs <- getMy.Line.Reciprocal.Explicit.Coeffs.FromExplicit(slope, intercept, r)
     recipSlope <- recipCoeffs$slope
     recipIntercept <- recipCoeffs$intercept
     intersectPt <- getMy.Line.Intersects.FromExplicit(slope, intercept, recipSlope, recipIntercept)
     return(intersectPt)
 }
 
 getMy.Line.Intersects.FromVectors <- function(p,v, pTick, vTick){
    oneCoeffs = getMy.Line.Explicit.Coeffs.FromVectors(p,v)
    twoCoeffs = getMy.Line.Explicit.Coeffs.FromVectors(pTick,vTick)
    slope = oneCoeffs$slope
    intercept = oneCoeffs$intercept
    slopeTick = twoCoeffs$slope
    interceptTick = twoCoeffs$intercept
    intersectPt <- getMy.Line.Intersects.FromExplicit(slope, intercept, slopeTick, interceptTick)
    return(intersectPt)
 }

 getMy.Line.Intersects.FromExplicit <- function(slope, intercept, slopeTick, interceptTick){
     #solve for the point where they cross
     #mx + b = m`x + b`
     #mx = m`x + b`- b
     #mx - m`x = b`- b
     #x(m - m`) = b`- b
     #x = (b`- b)/(m - m`)
     interceptX <- (interceptTick - intercept)/(slope - slopeTick)
    
     #plug that point back into either
     interceptY <- slope*interceptX + intercept
     return(c(interceptX, interceptY))
 }
 
 getMy.Convert.Degrees2Rotation <- function(a){
     aRad <- getMy.Convert.Degrees2Radians(a)
     myRotation <- matrix(c(cos(aRad),sin(aRad),-1*sin(aRad),cos(aRad)),ncol=2)
     return(myRotation)
 }
 
 getMy.Vector.Rotation <- function(v, angle){
     myR <- getMy.Convert.Degrees2Rotation(angle)
     vTick <- myR %*% v 
     return(vTick)
 }
 
 getMy.Vector.Shear <- function(v){
     vMatrix <- matrix(c(1,(-1*v[2]/v[1]),0,1), ncol=2)
     vTick = vMatrix %*% v
     return(vTick)
 }
 
 getMy.Vector.Projection.FromDegrees <- function(v,angle){
     ui <- getMy.Convert.Degrees2Radians(angle)
     u <- matrix(c(ui, ui),ncol=1)
     #defines projection matrix
     A <- u %*% t(u)
     vTick <- A %*% v
     return(vTick)
 }
 
 getMy.Vector.LinearArea <- function(a1, a2){
   T1 = 1/2*a1[1]*a2[1]
   T2 = 1/2*(a1[1] - a1[2])*(a2[2]-a2[1])
   T3 = 1/2*a1[2]*a2[2]
   
   T0 = a1[1] * a2[2] - T1 - T2 - T3 
   myMap <- data.frame(T1= abs(T1), T2= abs(T2), T3= abs(T3), T0 = abs(T0))
   return(myMap)
 }
 
 getMy.Vector.LinearAreaBox<- function(u,v, origin = c(0,0)){
   topRight <- c(max(c(u[1],v[1],origin[1])), max(c(u[2],v[2],origin[2])))
   bottomLeft <- c(min(c(u[1],v[1],origin[1])), min(c(u[2],v[2],origin[2])))
   topLeft <- c(bottomLeft[1],topRight[2])
   bottomRight <- c(topRight[1], bottomLeft[2])
   
   d <- data.frame(bottomLeft,bottomRight,topLeft,topRight)
   return(d)
 }
 
 #Sketch 6.1, Practical Linear Algebra, 3rd Edition
 getMy.Vector.AffineMap <- function(x,a1,a2,p = c(0,0),origin = c(0,0)){
    A <- matrix(c(a1,a2),ncol=2)
    xTick <- p + A %*% (x - origin)
 }
 
---- 

----
R Graphix
 x <- c(1,3,4,5,8)
 y <- c(2,4,7,3,9)
 plot(x,y) #basic, no labels
 plot(x,y, type="l", col="black", xlab="My X-axis label", 
           ylab="My Y-axis label", main="My Header label",
           font.main=2, font.lab=1,pch=19)
 par(mfrow=c(2,2)) #to show multiple graphs in the R Plot window
 
 #show a matrix of scatter plots 
 pairs(SomeData[1:7], cex.labels = 2, font.labels= 2)
 
 - anything beyond basic graphs uses external package ggplot2 for 2D
  - line types 
  0 = blank, 1 = solid, 2 = dashed, 3 = dotted, 
  4 = dotdash, 5 = longdash, 6 = twodash
  
 - bar graph
  - uses geom_bar as graph type
 # basic 
 mygroup <- c("grp1","grp2","grp3")
 myvals <- c(5.441,3.22,5.65)
 mydataframe <- data.frame(mygroup, myvals)
 ggplot(mydataframe, aes(x=mygroup, y=myvals)) + 
    geom_bar(stat="identity", fill="lightblue", colour="black")
 
 # with sub groupings
 mygroup <- c("a","a","a","b","b","b")
 mysubgroups <- c("x","y","z","x","y","z")
 myval <- c(3.18,2.8,2.74,2.26,3.11,1.47)
 mydataframe <- data.frame(mygroup, mysubgroups, myval)
 ggplot(mydataframe, aes(x = mysubgroups, y = myval, fill=mygroup)) + 
     geom_bar(position = "dodge", stat = "identity")
     
 - line graph
  - uses geom_line as graph type
 # basic
 myX <- c(1:10)
 myY <- rnorm(10)
 mydataframe <- data.frame(myX, myY)
 #this gets the x-axis to have a line per unit
 mydataframe$myX <- factor(mydataframe$myX)
 # the "group=1" tells the graph to use create a vertical line per unit
 ggplot(mydataframe, aes(x = myX, y = myY, group=1)) + geom_line()
 
 # two lines, dataframe is like a denormalized table join
 mygroup <- c(rep("A", 10), rep("B", 10))
 mysubgroups <- c(seq(1, 10), seq(1:10))
 myval <- rnorm(20)
 mydataframe <- data.frame(mygroup, mysubgroups, myval) 
 ggplot(mydataframe, aes(x = mysubgroups, y = myval, colour=mygroup)) + 
     geom_line()
     
 - scatter plot
  - uses geom_point as graph type
 myX <- rnorm(100,33,8.75)
 myY <- rnorm(100, 70, 9.96)
 mydataframe <- data.frame(myX, myY)
 #default is solid, shape=16, 21 is hollow
 ggplot(mydataframe, aes(x = myX, y = myY)) + geom_point(shape=21)
  
 - drawing classic empty graph
 mycoord <- getMy.Draw.CoordGraph(-2,10)
 #draw the vector
 mycoord <- getMy.Draw.Vector(mycoord, c(1,4))
 
 #draw the dotted lines in which the vector encloses a triangle
 mycoord <- getMy.Draw.Segment(mycoord, startVector = c(0,0), endVector = c(1,0))
 mycoord <- getMy.Draw.Segment(mycoord, startVector = c(1,0), endVector = c(1,4))
 #enclose the vector triangle with a color
 d <- data.frame(x=c(0,1,1), y=c(0,0,4), t=c("a","a","a"))
 mycoord <- mycoord + geom_polygon(data = d, mapping = aes(x = x, y = y, group = t), fill = "lightblue")
 
 - use rgl for 3D
 library(rgl)
 #makes is so that further commands are applied to the existing open window
 open3d()
 #create a blank 3D plot 
 x = seq(-5,5)
 y = seq(-5,5)
 z = seq(-5,5)
 plot3d(x, y, z, type="n") 
 #add a vector'esque arrow
 arrow3d(c(0, 0, 0), c(3, 4, 3), type = "lines", col = "green")
 #add plot lines inside the box
 abclines3d(0, 0, 0, a = diag(3), col = "gray")
 #add some floating text
 text3d(3,3,3,"(3,3,3)")
 #add a plane
 planes3d(1,0,0,0, alpha=0.5)
----

----
Convert degrees to radians
 - R only works in radians, not degrees
 - Circumference = 2*pi*r 
    where r is radius
 - want to work as r = 1
   C = 2 *pi, which is 360 degrees
 - so 180 degrees is just pi
 - degrees to radians (a / 1) * (pi / 180)
 - radians to degress a * 180/pi
----

----
Points & Vectors
 - most basic 2D a point is two coords
 - three or more points are collinear when 
   they all lie on a single line
 - two points are collinear since it takes 
   two points to form a line.
 
 - vector is a difference of two points
   which describes a direction and distance
  - the components of v is v1 and v2 which indicate
    a rise & run from point p
  - given just one vector the other one is presumed the 
    origin (0,0)
  
 - points and vectors are different geometric entities
  - distinguishing them it to achieve geometric constructs
    that are coordinate-independent.
  - coordinate-independent constructs are manipulations 
    applied to geometric objects that produce the same 
    result regardless of the location of the coordinate 
    origin.
  
 - in practice:
  - subtracting to points yields a vector
  - adding or subtracting two vectors yields another
    vector
  - adding a vector to a point yields another point

  - a 'well-defined' operation is one which is coordinate 
    independent
  - scaling a point (s*p) is not well-defined
  - scaling a vector (s*v) is well-defined
  - adding two points (p+q) is not well-defined since
    it is dependent on the coordinate origin
	
 - a Matrix is a map of vectors to vectors
 
 - Tensor order: how a value is indexed in a vector
   e.g. v[1]
   "tensors of unity order", the nature of indexing 
   a vector with a single index
   - scalars may be viewed as zero-order tensors
   - matrices are second-order tensors
   - a "cube" would be a 'Order 3 Tensor'
   - further dim's are just called 'Order N Tensor'
   
 - Hyperplane: a kind of cross-section of some
    set of dimensions, being one-less dimension than
    its container.
   - like the classic three dim graph from econ where
     we hold one dimension constant
 - Set: mutable unordered collection of unique and immutable objects
 - Relation: another name for a set of ordered pairs
   - can create graphs of relations which are not functions
----

----
Vector Length
 - may represent distance, velocity or acceleration
 - length of a vector is called magnitude
 - since a vector's components are the rise & run
   the vector's length may be assigned as the 
   hypotenuse of a right triangle
 - this is named the Euclidean norm 
 - in algebra, has the symbol like abs value |v| or ||v||

  getMy.Vector.EuclideanNorm(c(8,12))
 - a normalized vector has a unit length of one
  - normalized vectors are also known as unit vectors
  - not every vector is a normalized one
 - to normalize a vector is divide each component by 
   Euclidean norm (W = v/|V|)
   
   - example, not a normalized vector
  getMy.Vector.Normalized(c(3,7)) #[1] 0.3939193 0.9191450
   
  - example, a normalized vector
  getMy.Vector.Normalized(c(5, 0)) #[1] 1 0
   
 - the distance between two points is the
   Euclidean norm of the vector of the two points 

  getMy.Vector.Distance(c(-1,2),c(1,0)) #[1] 2.828427
----

----
Vector Space
 - start with idea of n-tuple
  - tuple is defined as an immutable sequences 
    of object references accessed by offset
  - its not a set because order matters
 - an n-tuple can represent a point in n-space
  - e.g. (1,5) is a point in 2D space
         (6,4,5) is a point in 3D space
 - n-space: this consist of all n-tuples
  - this is given a glyph of a kind of embossed 
    capital R with a superscript for the n
  - the R^n is therefore a set,
   - set is defined as a mutable unordered collection 
     of unique and immutable objects
   - implies that, therefore, each n-tuple in R^n 
     is unique
   - since each is unique if two are found with 
     the same value then they are the same thing
 - the n-tuple is a vector
 - the symbol which points-to the whole n-tuple 
   is usually written in caps or bold
  - sometimes a small arrow pointing to the right 
    above a symbol also means its a vector
 - an individual item therein, with an index subscript
   is called a component
  - a component is writtin in lowercase or italics
 - two operations are applicable to R^n 
  - componentwise addition (subtraction is just the same except minus)
   - e.g. X=Y, x1+y1, x2+y2, ... , xn+yn
  - scalar multiplication
    -e.g. X * a, x1 * a, x2 * a, ... , xn*a
 - vector space: the name for the concepts of R^n, 
    n-tuples and two operations
----

----
Linear Combination
 - two vectors are parallel they are called
    linearly dependent
 - not being the case is called
    linearly independent
 
 - linear combination is taking two 
   linearly independent vectors to make 
   a new vector using one of the 
   two ops applicable to R^n 
   - componentwise addition\subtraction
   - scalar multiplication
  - in R^2 (i.e. 2D classic graph)
   - scalar multiplication do something in the 
     same direction, extend, shrink, reverse, etc.
    myvector <- c(1,4)   
    mycoord <- getMy.Draw.CoordGraph(-5, 8)
    mycoord <- getMy.Draw.Vector(mycoord, myvector*2, lnColor = "red", vectorLabel = "x*2")
    mycoord <- getMy.Draw.Vector(mycoord, myvector, lnColor = "black", vectorLabel = "x")
    mycoord <- getMy.Draw.Vector(mycoord, myvector*-1, lnColor = "lightblue", vectorLabel = "x*-1")
    #times 2 just moves it out, twice as long, time -1 reverses it the other way
    mycoord
  
   - componentwise addition will find 
     the vector which bisects the space 
     between the two 
    myvectorY <- c(0.5,3)
    myvectorX <- c(3.2,1)
    mycoord <- getMy.Draw.CoordGraph(-2, 8)
    mycoord <- getMy.Draw.Vector(mycoord, myvectorY, lnColor = "black", vectorLabel = "y")
    mycoord <- getMy.Draw.Vector(mycoord, myvectorX, lnColor = "black", vectorLabel = "x")
    #unlike subtraction the order here doesn't matter
    myVectorSum <- myvectorY + myvectorX
    #blue line lies between the left and right
    mycoord <- getMy.Draw.Vector(mycoord, myVectorSum, lnColor = "lightblue", vectorLabel = "y + x")
    
    #the parallelogram is myvectorX starting at the tip of myvectorY
    # and likewise for myvectorY starting at the tip of myvectorX
    mycoord <- getMy.Draw.Segment(mycoord, myvectorY, myVectorSum)
    mycoord <- getMy.Draw.Segment(mycoord, myvectorX, myVectorSum)
    
    #to have the bisect vector end right on the parallelogram line, take the sum times 1/2
    mycoord <- getMy.Draw.Segment(mycoord, myvectorY, myvectorX)
    mycoord <- getMy.Draw.Vector(mycoord, myVectorSum * 0.5, lnColor = "coral", vectorLabel = "1/2*(x+y)")
    mycoord

   - componentwise subtraction is drawing a line from the 
     tip of one vector to the other then projecting that
     as its own vector from the origin
    myvectorY <- c(0.5,3)
    myvectorX <- c(3.2,1)
    myXminusY = myvectorX - myvectorY
    myYminusX = myvectorY - myvectorX
    mycoord <- getMy.Draw.CoordGraph(-5, 5)
    mycoord <- getMy.Draw.Vector(mycoord, myvectorY, lnColor = "black", vectorLabel = "y")
    mycoord <- getMy.Draw.Vector(mycoord, myvectorX, lnColor = "black", vectorLabel = "x")
    mycoord <- getMy.Draw.Vector(mycoord, myYminusX, lnColor = "lightblue", vectorLabel = "y-x")
    mycoord <- getMy.Draw.Vector(mycoord, myXminusY, lnColor = "lightgreen", vectorLabel = "x-y")
    
    #the line from tip of y to x is the same as the green vector
    mycoord <- getMy.Draw.Segment(mycoord, myvectorY, myvectorX)

    #the line from tip x to (x-y) is the same as y itself
    mycoord <- getMy.Draw.Segment(mycoord, myvectorX, myXminusY)
    
----

----
Spans and Planes
 - Span: all possible linear combinations
   for a given set of vectors.
  - Column Space: given a matrix, think of its columns 
    as individual vectors, then the span 
    of the matrix is named its column space
 - Plane: is a span in R^3 given two vectors 
   - can be visualized as two points in 3D space
   - use the origin as the third point (0,0,0) and
     you have a triangle in 3D space
   - extend each side of the triangle in all directions
     and you bisect the 3D space with a plane

   #example,detect if vector y is on plane defined by vector u,v     
   library(pracma)
   u <- c(0,2,6)
   v <- c(3,9,0)
   y <- c(1,4,3)
   A <- matrix(c(u,v,y),ncol=3)
   Areduced <- rref(A)
   myAlpha <- Areduced[1,3]
   myBeta <- Areduced[2,3]
   
   #equals the original y of (1,4,3) so this is on the plane
   myAlpha*u + myBeta*v
----

----
Combining Points
 - although not well-defined there is a way to 
   combine two points
  -given two points p and q, v = q-p, t is a scaler
 r = p + t*v
 r = p + t*(q-p) 
 r = p + tq - tp
 r = p - tp + tq
 r = (1-t)*p + tq
      t = |r-p| / (|r-p| + |q-r|) 
  (1-t) = |q-r| / (|r-p| + |q-r|)
  
 getMy.CombineTwoPoints <- function(p, q, r){
    myDen <- getMy.Vector.Distance(r,p) + getMy.Vector.Distance(q,r)
    t <- getMy.Vector.Distance(r,p) / myDen
    oneMinusT <- getMy.Vector.Distance(q,r) / myDen
    return(data.frame(t=t, oneMinusT = oneMinusT))
 }
  
 - example
 p <- c(2,4)
 r <- c(6.5,7)
 q <-c(8,8)
 getMy.CombineTwoPoints(p,q,r) # t = 0.75, (1-t) = 0.25
----

----
Dot Product
 - concerns the two vectors 
  - are they the same vector
  - are they perpendicular 
  - what angle to they form
 u*v = |u|*|v|*cos(theta)
 
 - in R there is already an op for this (%*%)
 u <- c(2,2)
 v <- c(0,3)
 uDotV <- u %*% v # uDotV[1,1] = 6
  
 #this will equal uDotV
 getMy.Vector.EuclideanNorm(u)*getMy.Vector.EuclideanNorm(v)*getMy.Vector.CosTheta(u,v)
 
 - is then used to define the cosine of two vectors
        w   
       7
      /.
     / .
    /  .
   /   .
  /    .
 /)____.___> v
 -solve for the angle (cosθ = v*w / |v|*|w|)
 
 u <- c(-1,2)
 v <- c(1,3)
 getMy.Vector.Angle(u,v)

 #eyeball it graphed, should look about right
 mycoord <- mycoord <- getMy.Draw.CoordGraph(-2, 4)
 mycoord <- getMy.Draw.Vector(mycoord, u, lnColor = "black", vectorLabel = "u")
 mycoord <- getMy.Draw.Vector(mycoord, v, lnColor = "black", vectorLabel = "v")
----

----
Orthogonal projection
 - "orthogonal": of or involving right angles
 - the orthogonal projection of w onto v is defined as (u = ((v * w)/|v|^2) * v)
 - this is used alot graphically to project 3D images onto 2D
  - its alot like High School art classes "vanishing point", only mathematical
  
 v <- c(-1,1)
 w <- c(3,2)
 u <- getMy.Vector.OrthoProj(v,w)
 uUpsideDownT <- w - u
 mycoord <- getMy.Draw.CoordGraph(-5,5)
 mycoord <- getMy.Draw.Vector(mycoord, v, lnColor="black", vectorLabel="v")
 mycoord <- getMy.Draw.Vector(mycoord, w, lnColor="black", vectorLabel="w")
 mycoord <- getMy.Draw.Vector(mycoord, u, lnColor="lightblue", vectorLabel="u")
 mycoord <- getMy.Draw.Vector(mycoord, uUpsideDownT, lnColor = "lightblue", vectorLabel = "u┴")
 # the u┴ is at 90 degrees from v
 getMy.Vector.Angle(v,uUpsideDownT)
----

----
Lines defined
 - different ways to specify a line geometrically
  - two points on a single line
  - one point and one vector on a line
  - one point and one vector perpendicular to the line
 - likewise, there are different was to specify a line
   mathematically
  - parametric
  - implicit
  - explicit
  
 - Parametric equation of a line
  l(t) = p + tq
  l(t) = (p1, p2) + t(q1,q2)
  - this form is a.k.a. linear interpolation
  - can be used to find points on a line 
    given two points (q and p)
  mycoord <- getMy.Draw.CoordGraph(-2, 5)
  myP <- c(-1,1)
  myQ <- c(2,3)
  sumPandQ <- myP + myQ
  mycoord <- getMy.Draw.Vector(mycoord, myP, lnColor = "black", vectorLabel = "p")
  mycoord <- getMy.Draw.Vector(mycoord, myQ, lnColor = "black", vectorLabel = "q")
  mycoord <- getMy.Draw.Vector(mycoord, sumPandQ, lnColor = "lightblue", vectorLabel = "p + q")
  #this is the line as just a segment, its parallel to q
  mycoord <- getMy.Draw.Segment(mycoord, myP, sumPandQ)
  #so q is the rise/run (slope)
  mySlope <- myQ[2]/myQ[1]
  #can see that from p[2] + slope is where dashed line would cross y axis
  myIntercept = myP[2] + mySlope
  myLine <- function(x) mySlope*x + myIntercept
  myX <- seq(-2,5)
  myY <- sapply(myX, myLine)
  mycoord <- getMy.Draw.Line(mycoord, myX, myY)
  
 - Implicit equation of a line
  a*x1 + b*x2 + c = 0
   a = a1
   b = a2
   c = a1*p1 - a2*p2

  p <- c(2,2)
  q <- c(6,4)
  myImpVars <- getMy.Line.Implicit.Coeffs.FromVectors(p,q) #a=-2, b=4, c=-4
  myImplicitEq <- function(x) myImpVars$a*x[1] + myImpVars$b*x[2] + myImpVars$c
  # you can't use this like an explicit one and graph something
  # but you can test if a vector is on the line
  myImplicitEq(c(2,2)) #0, this is on the line
  myImplicitEq(c(-5,-5)) #-14, not on the line
  # to avoid floating point errors, divide by Eucl norm
  # d = (a*x[1] + b*x[2] + c) / |a|
  
 - Explicit equation of a line y = f(x1, ... xn)
  x2 = ~a * x1 + ~b
  - where, using implicit variables, ~a is -a/b and ~b = -c/b
  
  p <- c(2,2)
  q <- c(6,4)
  myExpLine <- getMy.Line.Explicit.Fx.FromVectors(p,q)
  x <- seq(-10,10)
  y <- sapply(x, myExpLine)
  #draw the line
  mycoord <- getMy.Draw.CoordGraph(-10,10)
  mycoord <- getMy.Draw.Line(mycoord, x, y, "red")
  #add the points to confirm it worked
  mycoord <- mycoord + geom_point(aes(x = p[1], y = p[2]))
  mycoord <- mycoord + geom_point(aes(x = q[1], y = q[2]))
  
  - this the classic form with intercept and slope
  - has a left side for dependent variable and a right side
    for independent variable(s)
  - also known as Cartesian Equation
  - ~a is the slope (rise/run) 
   - slope is formally defined as tan(θ)
   - problem with explicit form is flat lines
     have and infinite slope
  - explicit to implicit always possible
  - implicit to explicit maybe possible
    x^2 + y^2 - 9 = 0 
   - this is a 'relation' not a function 
     because there is not a unique value of
     y for each value of x (it plots to a circle)
   - add in a restriction of y-is-always-positive and
     it could be a function (plots as the upper half of a circle)
----
   
----
Line Equation conversion
 - Parametric to Implicit
  l(t) = p + tq        parametric
  a*x1 + bx2 + c = 0   implicit
   a = [-q2, q1]
   c = -(a1*p1 + a2*p2)
   
 - Implicit to Parametric 
  a*x1 + bx2 + c = 0   implicit
  l(t) = p + tq        parametric
   q = [b, -a]
   p = [-c/a,0] -or- [0,-c/b]
      choose by whichever is greatest
	   abs(a) > abs(b), choose [-c/a,0]
	   abs(a) < abs(b), choose [0,-c/b]
 
 - Explicit to Parametric
  x2 = a*x1 + b
  x = (x1, x2)
    = (x1, a*x1 + b)
    = (0,b)+(x1,a*x1)
    = (0,b)+ x1*(1,a)
----

----
Distance of a Point to a Line
 - given any point (r) and line (l)
   how far is r from l
 d = |a*x1 + b*x2 + c| /sqrt(a^2 + b^2)
 
 #l: -2x + 3y + 4 = 0
 #r: (5,6)
 r <- c(5,6)
 d = getMy.Line.Distance.Point.FromImplicit(-2,3,4,r) #3.328201
----

----
Foot of a given point
 - given some line (l) and some point (r)
   which point on (l) is closest to (r) 
   known as (q)
 - when drawing a line from r to l, the optimal
   solution is one that closest to 90 degrees to (l)
   passing through (r)
  exampleRange = c(-10,10)
  mycoord <- getMy.Draw.CoordGraph(exampleRange[1],exampleRange[2])
  middleRiseP <- c(-1,3)
  middleRiseQ <- c(2,-1)
  middleRiseR <- c(5,5)
  mycoord <- getMy.Draw.Point(mycoord,middleRiseP,"#FF51F3")
  mycoord <- getMy.Draw.Point(mycoord,middleRiseQ,"#FF51F3")
  mycoord <- getMy.Draw.Point(mycoord,middleRiseR,"#FFFF60")
  middleRiseFx <- getMy.Line.Explicit.Fx.FromVectors(middleRiseP, middleRiseQ)
  middleRiseXvals <- seq(exampleRange[1], exampleRange[2])
  middleRiseYvals <- sapply(middleRiseXvals, middleRiseFx)
  mycoord <- getMy.Draw.Line(mycoord, middleRiseXvals, middleRiseYvals, "#FBAFFF")
  middleRiseRecipCoeffs <- getMy.Line.Reciprocal.Explicit.Coeffs.FromVectors(middleRiseP,middleRiseQ,middleRiseR)
  middleRiseRecipFx <- function(x) middleRiseRecipCoeffs$slope * x + middleRiseRecipCoeffs$intercept
  middleRiseRecipXvals <- seq(exampleRange[1], exampleRange[2])
  middleRiseRecipYvals <- sapply(middleRiseRecipXvals, middleRiseRecipFx)
  mycoord <- getMy.Draw.Line(mycoord, middleRiseRecipXvals, middleRiseRecipYvals, "#63FF6B")
  crossPt <- getMy.Line.Closest.Point.FromVectors(middleRiseP,middleRiseQ,middleRiseR)
  mycoord <- getMy.Draw.Point(mycoord,crossPt,"#FF1418")
  
  implicitCoeffs <- getMy.Line.Implicit.Coeffs.FromVectors(middleRiseP, middleRiseQ)
  #these will equal
  calcDist <- getMy.Vector.EuclideanNorm(crossPt - middleRiseR)
  actualDist <- getMy.Line.Distance.Point.FromImplicit(implicitCoeffs$a,implicitCoeffs$b,implicitCoeffs$c,middleRiseR)
----

----
Parametric & Implicit Solve for intersect 
 line_1: l(t) = p + t * v
 line_2: a*x1 + b*x2 + c = 0
 
 - find the parameter (t) with respect 
   to line_1
 - vLen is short-hand for getMy.Vector.EuclideanNorm
  vLen <- function(x) getMy.Vector.EuclideanNorm(x)
 - plug-in line1 into line2
  a * [p1 + t * v1] + b * [p2 + t * v2] + c = 0
 - solve for t
 
  t = (-c - a * p1 - b* p2) / (a * v1 + b * v2)
 - if the denominator is zero the two lines are 
   parallel and never intersect
 - check for parallel before solving using 
   by calc cosine of a * v
  cosθ = a*v / vLen(a) * vLen(v)
   - computational tolerance around cos(0.1) 
     and cos(0.5)
 - furthermore, these may be the same lines 
  d = (a*p1 + b*p2 + c) / vLen(a)
   - are the same line if (d) equals zero
 
  -example
   line_1: l(t) = [0,3] + t * [-2,-1]
   line_2: 2*x1 + x2 - 8 = 0
 
  p <- c(0,3)
  v <- c(-2,-1)
  ab <- c(2,1)
  c <- -8
  
  myDenom <- sum(ab * v) #no eq zero
  t <- (-1*c - sum(ab * p)) / myDenom
  
  #use t to solve line_1
  myIntersect <- p + t * v # [2,4]
----

----
Matrix Laws & Names
 - not commutative multiplication
   AB != BA
   
 - associative multiplication
  A*(B*C) = (A*B)*C
  (a*b)*C = a*(b*C)
  a*(B*C) = (a*B)*C = B*(a*C)
  
 - distributive law
  A*(B + C) = A*B + A*C
  (B + C)*A = B*A + C*A
  A*v + B*v = (A + B)*v
  [A + B]ᵀ = Aᵀ + Bᵀ
  A*(u + v) = A*u + A*v
  
 - commutative addition
  A + B = B + A
  
 - associative addition
  A + (B + C) = (A + B) + C
  
 - symmetric matrix is 
   A = Aᵀ
 - dyadic matrix
   A*Aᵀ
 - idempotent matrix
   A = A*A
 
 - other multiplication rules
  (A*B)ᵀ = Bᵀ*Aᵀ
  det(A * B) = det(A) * det(B)
 
 - exponent rules
   A^(r+s) = A^r * A^s
   A^(r*s) = (A^r)^s
   A^0 = I

 - inversion rules
  A^-1*A = I
  A*A^-1 = I
  I^-1 = I
 (A^-1)^-1 = A
 (A^-1)ᵀ = (Aᵀ)^-1
   
----

----   
Reflection 
 - is like flipping & rotating on an axis
  -example
   # flipped along x-axis 
   myR <- matrix(c(1,0,0,-1), ncol=2)
   v <- c(2,4)
   vTick <- myR %*% v 
   mycoord <- getMy.Draw.CoordGraph(-5, 5)
   mycoord <- getMy.Draw.Vector(mycoord, v, "red")
   mycoord <- getMy.Draw.Vector(mycoord, vTick, "blue", "flipped at x-axis")
   
   myR <- matrix(c(0,1,1,0), ncol=2)
   vTick <- myR %*% v # [4,2], x & y swapped places
   mycoord <- getMy.Draw.CoordGraph(-5, 5)
   mycoord <- getMy.Draw.Vector(mycoord, v, "red")
   mycoord <- getMy.Draw.Vector(mycoord, vTick, "blue", "swapped")
   
   #opposite direction
   myR <- matrix(c(-1,0,0,-1), ncol=2)
   vTick <- myR %*% v 
   mycoord <- getMy.Draw.CoordGraph(-5, 5)
   mycoord <- getMy.Draw.Vector(mycoord, v, "red")
   mycoord <- getMy.Draw.Vector(mycoord, vTick, "blue", "did a 180, knarly!")
   
 - rotation matrix is given as where (a)
   is the desired angle of rotation
      .-             -.   .- -.
  R = | cos(a) -sin(a)| * |v1 |
      | sin(a)  cos(a)|   |v2 |
      `-             -'   `- -'
   mycoord <- getMy.Draw.CoordGraph(-5, 5)
   mycoord <- getMy.Draw.Vector(mycoord, v, "red")
   for(i in seq(47,180,15)){
      vTick <- getMy.Vector.Rotation(v,i)
      myAngle <- sprintf("(%s°)",i)
      mycoord <- getMy.Draw.Vector(mycoord, vTick, "blue", myAngle)
   }
----

----
Shears
 - tilt like how italic fonts look to regular
     .-       -.   .- -.
 v'= |     1  0| * |v1 |
     |-v2/v1  1|   |v2 |
	 `-       -'   `- -'
 - example
 v <- c(2,5)
 mycoord <- getMy.Draw.CoordGraph(-5, 5)
 mycoord <- getMy.Draw.Vector(mycoord, v, "red")
 vTick = getMy.Vector.Shear(v)
 mycoord <- getMy.Draw.Vector(mycoord, vTick, "blue")
----

----
Projections
 - like sunlight casting shadows
 - parallel projections are having all vectors
   projected in a parallel direction
 - when the angle of incidence is 90 degrees
   then its an orthogonal projection
 - otherwise known as an oblique projection
 
 - example
  #projection of v by 45 degrees
  v <- c(1,2)
  vTick <- getMy.Vector.Projection.FromDegrees(v,45)
  mycoord <- getMy.Draw.CoordGraph(-1, 5)
  mycoord <- getMy.Draw.Vector(mycoord, v, "red")
  mycoord <- getMy.Draw.Vector(mycoord, vTick, "blue")
----

----
Linear Maps and Area
 - getting the area given two vectors
      .-   -.
  a = | 2 4 |
      | 6 3 |
      `-   -' 
   |____________(a1)_________________________
 4-|             7_______            T2      |
   |            /        ---______           |
   |           /                  -----______|
 3-|  T3      /                           __-7(a2)
   |        /                          _--   |
   |       /         T            __---      |
 2-|      /                    _--           |
   |     /                __---              |
   |   /              _---                   |
 1-|  /          __---                       |
   | /    ____---                T1          |
   |/__---                                   |
 0-|-------------------------------------------
   |      |      |      |      |      |      | 
   0      1      2      3      4      5      6 
 
  - it is possiable to calc the area of each
    triange (T, T1, T2, T3)
   T1 = 1/2*a[1,1]*a[2,1]
   T2 = 1/2*(a[1,1] - a[1,2])*(a[2,2]-a[2,1])
   T3 = 1/2*a[1,2]*a[2,2]
   T = a[1,1] *a[2,2] - T1 - T2 - T3
  
  - determinant is given a 2*T
  
  a1 <- c(2,4) 
  a2 <- c(6,3)
  myArea <- getMy.Vector.LinearArea(a1,a2)
  mapPoints <- getMy.Vector.LinearAreaPoints(a1,a2)
  mycoord <- getMy.Draw.CoordGraph(-1, 7)
  mycoord <- getMy.Draw.Vector(mycoord, a1)
  mycoord <- getMy.Draw.Vector(mycoord, a2)
  mycoord <- getMy.Draw.Segment(mycoord, a1,a2)
  mycoord <- getMy.Draw.Segment(mycoord, mapPoints$bottomLeft, mapPoints$bottomRight, "red")
  mycoord <- getMy.Draw.Segment(mycoord, mapPoints$bottomRight, mapPoints$topRight, "red")
  mycoord <- getMy.Draw.Segment(mycoord, mapPoints$bottomLeft, mapPoints$topLeft, "red")
  mycoord <- getMy.Draw.Segment(mycoord, mapPoints$topLeft, mapPoints$topRight, "red")
  mycoord <- mycoord + annotate("text", x=2.5, y=0.5, label=sprintf("T1=%s",myArea$T1))
  mycoord <- mycoord + annotate("text", x=0.5, y=3, label=sprintf("T3=%s",myArea$T3))
  mycoord <- mycoord + annotate("text", x=4.5, y=3.67, label=sprintf("T2=%s",myArea$T2))
  mycoord <- mycoord + annotate("text", x=2.5, y=2.25, label=sprintf("T0=%s",myArea$T0))
  mycoord
----

----
Linear System (2X2)
 - defining two linear eq's in 
   matrix format
 - Linear Map is formally defined as
    v' = A*v 
   - in that it preserves linear combinations of
     vectors.   
	
  2*u1 + 4*u2 = 4
    u1 + 6*u2 = 4
	-as-
  .-   -.   .- -.   .--.
  | 2 4 |   |u1 |   |4 |
  | 1,6 | * |u2 | = |4 |
  '-   -'   `- -'   `--'
 
  - the possiable solutions is named
    solution space
  - roughly divided into 
   (1) exactly on solution vector (u)
       when det(A) != 0
   (2) there is no solution whatsoever
   (3) there are an infinite many solutions
----

----
Cramer's rule
 - based on the geometry of the parallelograms
   formed by a linear system
   a <- matrix(c(2,1,4,6),ncol=2)
   b <- matrix(c(4,4), ncol=1)
   
   u1Numer <- matrix(c(b[1,1],b[2,1],a[1,2],a[2,2]), ncol=2)
   u2Numer <- matrix(c(a[1,1],a[2,1],b[1,1],b[2,1]), ncol=2)
   uDemon <- matrix(c(a[1,1],a[2,1],a[1,2],a[2,2]), ncol=2)
   
   u1 <- det(u1Numer) / det(uDemon)
   u2 <- det(u2Numer) / det(uDemon)
----

----
Gauss Elimination
 - involves tech terms of 
 - back substitution: where we solve for 
   u2 then use its solution-value to solve for u1
  u1 = b2/a2,2
  u1 = 1/a1,1 * (b1 - u2*a1,2)
   
 - foward elimination: the process of getting a[2,1] to equal 0
    which is required for back-sub to work.
 - gauss elimination: the process of foward-elim. followed by
   back sub.
  - based on rule that linear maps do not change linear combos.
    which means applying a linear map to all vectors will not 
	change u1, u2.
 
 - get a[2,1] to zero can be done using a Shear, defined as
  - re-write into column form so Algebraically looks like
                .-    -.        .-    -.              .-    -.
                |a[1,1]|        |a[1,2]|              |b[1,1]|
   shearA*(u1 * |a[2,1]| + u2 * |a[2,2]| ) = shearA * |b[2,1]|
                `-    -'        `-    -'              `-    -'
   a <- matrix(c(2,1,4,6),ncol=2)
   
   #break matrix a into two columns
   aCol1 <- matrix(c(a[1,1],a[2,1]), ncol=1)
   aCol2 <- matrix(c(a[1,2],a[2,2]), ncol=1)
   b <- matrix(c(4,4), ncol=1)
   
   #calc shear
   shearA <- matrix(c(1,(-1*a[2,1]/a[1,1]),0,1), ncol=2)
   
   #take shear time each column
   newACol1 <- shearA %*% aCol1
   newACol2 <- shearA %*% aCol2
   newB <- shearA %*% b
   
   #put it back together as a linear system, completes foward-elim.
   newA <- matrix(c(newACol1[1,1], newACol1[2,1], newACol2[1,1], newACol2[2,1]), ncol=2)
   
   #back sub.
   u2 = newB[2,1] / newA[2,2]
   u1 = (1/newA[1,1])*(newB[1,1] - u2*newA[1,2])
----

----
Pivoting
 - idea or rearranging the linear solution so a shear may 
   be calc'ed and thereby back sub.
 .-   -.   .-  -.   .- -.
 | 0 1 |   | u1 |   | 1 |
 | 1 0 | * | u2 | = | 1 |
 `-   -'   `-  -'   `- -'
  - a[1,1] is zero and we can't divide by zero
  - as eq's they would look like
  0*u1 + 1*u2 = 1
  1*u1 + 0*u2 = 1
  - then flip the order of them
  1*u1 + 0*u2 = 1
  0*u1 + 1*u2 = 1
  - and convert back to linear system
 .-   -.   .-  -.   .- -.
 | 1 0 |   | u1 |   | 1 |
 | 0 1 | * | u2 | = | 1 |
 `-   -'   `-  -'   `- -'  
 - there is likewise ability to perform 
   column pivoting
 .-     -.   .-  -.   .- -.
 | 0 1/2 |   | u1 |   | 0 |
 | 0   0 | * | u2 | = | 0 |
 `-     -'   `-  -'   `- -'
  - to
  0*u1 + 1/2*u2 = 0
  0*u1 +   0*u2  = 0
  - flipped as
 1/2*u2 + 0*u1 = 0
   0*u2  + 0*u1 = 0
  -back to linear system
 .-     -.   .-  -.   .- -.
 | 1/2 0 |   | u2 |   | 0 |
 | 0   0 | * | u1 | = | 0 |
 `-     -'   `-  -'   `- -'
----
   
----
Inverse ops & Maps
 - applying an inverse is a form of undo'ing 
   a linear map
 A*u = b
  -then-
 u = A^-1*b
 
 - given two vectors which are known to map
   to two other vectors, solve for the Matrix
 
 A*v1 = v'1
 A*v2 = v'2
 A*(v1, v2) = v'1,v'2
  -shortened as-
 A*V = V'
 A = V'*V^-1
 - insuch a case the application of matrix
   A is known as "change of basis"
   
 -example
  v1 <- c(1,1)
  v2 <- c(-1,1)
  
  vTick1 <- c(-1,-1)
  vTick2 <- c(1, -1)
  
  V <- matrix(c(v1[1],v1[2],v2[1],v2[2]),ncol=2)
  V2neg1 <- solve(V)
  
  VTick <- matrix(c(vTick1[1],vTick1[2],vTick2[1],vTick2[2]),ncol=2)
  A <- VTick %*% V2neg1
---- 

----
Affine maps 
 - linear map was to map vector to vector
 - affine is to map points to points
  - affine maps are to move and orient
    objects like in visual graphics
  - are composed of components named
   - translation (p): an object is moved
      w/o changing its orientation
   - linear map (A)
  - while linear maps are releated to ratios
    affine maps leave ratios unchanged
   
  x' = p + x1*a1 + x2*a2
  x' = p + A*x
  
  - the x' has the same coordinates 
    in the new system that x did in the 
	former

  - technically the linear map A is 
    applied to the vector x - o
	where o is the (0,0) of the 
	former coordinate system
  x' = p + A*(x - o)
  
 - Translation, as a affine map is written 
   as  
  x' = p + I*x
----

----
General Affine maps
 - Rotate: have point r and want to rotate
   some pt (x) by (a) degrees
  x' = A*(x - r) + r
  
  -example
  A <- getMy.Convert.Degrees2Rotation(90)
  r <- c(2,1)
  x <- c(3,0)
  
  A %*% (x - r) + r # (3,2)
 
 - Reflect: have line (l) and point (x)
   and want to reflect (x) across line (l)
  - uses the "Foot of a given point" where its
    value (here called (p)) is the mid-pt 
	of the reflection
  p = 1/2*x + 1/2*x'
  x'= 2p - x
----

----
Digression on Statistics 
 - Variance, how wide the obs are spead along an axis
 - Covariance, indicates the positive or negative relationship
    amoung obs 
 - Clustering, divide obs into groups
 - Correlation, measure strength and direction of two
   obs 
 - Probability, P(E) = (Chances for E)/(Total Chances)
   - probability of an Ace in a common deck of cards
     P(Ace) = (4)/(52)
 - Odds, (Chances for E)/(Chances Against E)
   - odds of an Ace is 
     Odds(Ace) = (4) /(52-4)
 - normal distribution, the classic bell-curve
   - also known as Gaussian distribution
 - other distributions 
   - Binomial
   - Inverse Gaussian
   - Log normal
----

----
Simple Linear Regression
 - linear positive slope is also called 
    concordant association
 - linear negative slope is also called
    discordant association
 
 - start with equation y = a * x + b
 - data is a plot so its can be rep'ed as matrix
    .-  -.   .-     -.   
    | y1 |   | x1  1 |   .- -.
    | y2 | = | x2  1 | * | a |
    | .. |   | ..  . |   | b |
    | yn |   | xn  1 |   '- -'
    '-  -'   '-     -'
 - assign each matrix to a symbol
      Y = X * A
 - solve for A
      A = X\Y

 #the first arg is 'formula' - which has it own operators
 #tilde '~' (x7E), right side is the 'response', left side is the 'model'
 LinearModel = lm(SomeData$FieldTwo ~ SomeData$FieldOne, data = SomeData)
 
 #get a summary about the linear regression
 summary(LinearModel)
 
 #get just the coefficents
 LinearModel$coefficients
 
 #get R-squared value
 summary(LinearModel)$r.squared
 
 #plot 5 different esoteric graphs
 plot(LinearModel)
 plot(LinearModel, which=1)

 - to get an idea of the "perfect version" of these esoteric graphs
 #start with a full linear eq
 x<-seq(1,100,0.1)
 
 #f(x) = -2.7x + 6
 y<-2.7*x+6
 
 #add in a little variance
 er<-runif(length(y), min = -1, max = 1)
 y<-y+er
 
 #and plot this hack
 dataxy<-table(rep(x, y))
 LModel<-lm(y~x, data = dataxy)
 plot(LModel)
----
 
----
Multiple Linear Regression
 - start with equation y = b0 + b1*x1 + b2*x2 + ... + bn*xn
 - data is a plot so its can be rep'ed as matrix
    .-  -.   .-                   -.   .-  -.
    | y1 |   | 1 x1,1 x1,2 ... x1,n|   | b0 |
    | y2 | = | 1 x2,1 x2,2 ... x2,n| * | b0 |
    | .. |   | ..                  |   | .. |
    | yn |   | 1 xn,1 xn,2 ... xn,n|   | bn |
    '-  -'   '-                   -'   '-  -'
 - assign each matrix 
      Y = X * B
 - solve for B
    B = (Xᵀ * X)^-1 * Xᵀ * Y
    
  CementData = read.csv("CementData.csv", header = TRUE, sep = ",")
  
  #data as a matrices
  columnOfOnes = rep(1,13)
  x <- as.matrix(columnOfOnes, CementData[,1:4]))
  y <- CementData[,5]
  Beta <- solve(t(x) %*% x) %*% t(x) %*% y
  
  #get the residual of predicted versus observed
  YRegFit <- x %*% Beta[,1]
  Residual= y-YRegFit
  
  #calc the R-squared
  Rsqr = 1 - sum((y - YRegFit)^2)/sum((y - mean(y))^2)
  
  #using builtin R model
  PetroData = read.csv("EscapingHydrocarbons.csv", header = TRUE, sep = ";")
  
  #has fields with long names
  #plus-sign '+' (x2B), is to make the model a multiple linear regression
  MLModel = lm(AmountEscapingHydrocarbons ~ TankTemperature + PetrolTemperature + InitialTankPressure + PetrolPressure, 
               data = PetroData)
----

----
Categorical variables
 - are not from measurements
 - are for classification
 - Nominal Categorical variables: 
  - have two or more categories
  - have no intrinsic order or hierarchy
 - Dichotomous Categorical variables:
  - special case of nominal variables
  - have only two possible values
 - Ordinal Categorical variables,
  - have two or more categories
  - can be ordered and ranked
  
  library(readxl)
  EmployeesSalary <- read_excel("employees.xlsx")
  
  #investigate if a character vector is a category
  unique(EmployeesSalary$LevelOfEmployee)
  
  #character vector reassigned as a factor vector (like an enum)
  EmployeesSalary$LevelOfEmployee <- as.factor(EmployeesSalary$LevelOfEmployee)
  
  #scatter plot by the factor variable
  pch.list <- as.numeric(EmployeesSalary$)
  
  #star '*' (x2A), is to make the model by category
  # formula is now a string literal - text offers no explaination
  LMcat <- lm('Salary~YearsExperience*LevelOfEmployee', data = EmployeesSalary)
----

----
Gradient Descent and Linear Regression
 - pragmatic approach to get the regression 
 - is a supplementary method to the B = (Xᵀ * X)^-1 * Xᵀ * Y
  - the matrix algebra approach will overheat the machine for big data
  - may also be that Xᵀ * X does not exist
 - starts with a cost function that takes a,b and returns an error value
  - error value represents how well the a,b actually fits the data
  
  CostFunction = 1/N * ((SUM(y[i] - (a*x[i] + b))^2)|i=1 to i=n)
   - this is iterated, adjusting a,b each time
   - in 3-D space the CostFunction forms a concave graph
   - since there are two variables, we need a hyperplane along each a,b
    - del is for the partial derivative backward 6 symbol thing
   del/del a = 2/N * (SUM(-x[i] * (y[i] - (a*x[i] + b)))|i=1 to i=n)
   del/del b = 2/N * (SUM(-(y[i] - (a * x[i] + B)))|i=1 to i=n)
   
   - next is the iterative part where
   a[n+1] = a[n] - (eta) * (del/del a[n])
   b[n+1] = b[n] - (eta) * (del/del b[n])
    - eta is the step-size, 
     - too big may over step the min, 
     - too small may take too long
----

----  
Stochastic Gradient Descent
 - like the previous only it works by taking a sample of 
   the data at random
 - likewise imporves performance 
 
  #import stochastic gradient descent lib
  library(sgd, warn.conflicts = FALSE)
  
  #make a data set 
  N <- 10000
  d <- 10
  
  #set the seed for global R random genr'ator
  set.seed(42)
  
  #create a random matrix as explanatory variables
  X <- matrix(rnorm(N*d),ncol=d)
  
  #the estimator
  theta <- rep(5,d+1)
  
  #some random error
  eps <- rnorm(N)
  
  #the response variable
  y <- cbind(1,X) %*% theta + eps
  
  #model with sgd
  dat <- data.frame(y=y, x=X)
  
  #"y ~ ." is the formula where '.' means "and all the rest"
  # 'model="lm"' is the kind of model, also has (glm, cox, gmm, m)
  sgd.theta <- sgd::sgd(y ~ ., data=dat, model="lm")
  
  - Mean Square Error (MSE)
  MSE = 1/n * (SUM((theta_tick - theta)^2)|i=1 to i=n)
  
  myMse <- mean((theta - as.numeric(sgd.theta$coefficients))^2)
  
  #a graph of the the MSE over the iterations
  plot(sgd.theta, theta, type="mse-param")
----

----
Polynomial Regression
 - kinda looks like equation for Multiple Linear Regression
 - but now there are exponents 
 y = b0 + b1*x + b2*x^2 + b3*x^3 + ... + bn*x^n
 
 # given the data
 Time=c(6,7,8,9,10,11,12,13,14,15,16,17,18,19)
 Temp=c(4,6,7,9,10,11,11.5,12,12,11.5,11,10,9,8)

 # meaning 
 # Temp = b0 + b1*Time + b2*Time^2
 
 #polynomial (long way) in R
 Polyfit2 <- lm(Temp ~ Time + I(Time^2))
 Polyfit3 <- lm(Temp ~ Time + I(Time^2) + I(Time^3))
 
 #polynomial (short way) in R
 Polyfit2b <- lm(Temp ~ poly(Time, 2, raw=TRUE))
 Polyfit3b <- lm(Temp ~ poly(Time, 3, raw=TRUE))
 
 #coefficients
 Polyfit2b$coefficients
 
 #no built-in to plot polynomials with R plot
 # get the Time axis as a sequence
 PredData = data.frame(Time = seq(min(Time), max(Time), length.out = 100))
 
 #use it to get the y 
 PredData$Temp = predict(Polyfit2b, newdata= PredData)
 
 #plot the two - pretty
 plot(Time, Temp)
 with(PredData, lines(x = Time, y = Temp))
----

----
Logistic Regression
 - probability of having an attribute in relation to the 
   number of possible variations of multiple explanatory 
   variables
 - each response variable is expected to be a kinda True\False
  - this known as a Bernoulli variable
 - if observations can only be (0,1) then the plot would 
   look like a bunch of dot along the two axis
   
   1 -|    o   o         o o   o o
      |
      |
      |
   .5-|
      |
      |
      |
   0 -|o o   o   o o o o     o
      +------------------------------
           observation ordinal 

   - a linear regression would peirce the 0 and 1 axis and 
     continue on - this wouldn't be right cause its senseless
   - we need the equation which goes from 0 to 1 and that's it
   
   - the linear form was, 
    - P(x) is "probability of x"
    - since this is just True\False
   P(x) = a*x + b 
   
   - put it as an exponent of 'e' and you remove the problem of 
     going to infinity on the negative side
   P(x) = e^(a*x + b)
   
   - put it as a ratio like this and you lock in the range 
   P(x) = e^(a*x + b)/(1 + e^(a*x + b))
   
   - solve for odds as
   P(x)/1 - P(x) = e^(a*x + b)
   log(P(x)/1 - P(x)) = a*x + b
----

----
Generalized Linear Model (GLMs)
 - where the reponse variable is discrete and the error terms do not 
   follow a normal dist
 - allow the mean to depned on explanatory variables through a 'link' function
   and the response variable to be any member of a set of distributions called 
   exponential family (i.e. Binomial, Gaussian, Poisson, etc.)
  
  - a simple example
  #make our data
  diabetes <- matrix(c(326,160,8,64), nrow=2) 
  colnames(diabetes) <- c("DiabNO", "DiabYes") 
  rownames(diabetes) <- c("StressNO", "StressYes")  
  TableDiabetes <- as.table(diabetes)
  DfBiabetes <- as.data.frame(TableDiabetes) 
  
  #get the logistic model
  LogModel <- glm(Var2 ~ Var1, weights = Freq, data = DfBiabetes, family = binomial(logit))
  
  Beta = LogModel$coefficient[1]
  Alpha = LogModel$coefficient[2]
  
  #P(x) = e^(a*x + b)/(1 + e^(a*x + b))
  P0 <- exp(Alpha*0 + Beta)/(1 + exp(Alpha*0 + Beta))
  P1 <- exp(Alpha*1 + Beta)/(1 + exp(Alpha*1 + Beta))
  odds0 <- P0 / (1 - P0)
  odds1 <- P1 / (1 - P1)
  OR1 <- odds1 / odds0
  # the odds that having this event will raise the chance of the other
----

----
Multiple Logistic Regression
 - like before, want to model on many variables
 - P(x) = b0 + b1*x1 + b2*x2 + ... + bn*xn 
  - with logistic transformation
  - P(x) = e^(b0 + b1*x1 + b2*x2 + ... + bn*xn) / 1 + e^(b0 + b1*x1 + b2*x2 + ... + bn*xn)
 
 #get data with multiple features
 someData <- read.csv("MyData.csv", sep=",", header = TRUE)
 
 #define the relation between explanatory (input) and response variables (output)
 formula1=MyResponseVar ~ MyFeature00 + MyFeature01 + MyFeature02
 LGModel1 <- glm(formula1, data = someData, family = binomial(logit))

 #get the predictions based on the model
 LGModel1Pred <- round(predict(LGModel1, data, type="response") 

 #use this to id the classification errors
 library(caret) 
 LGModel1 <- caret::confusionMatrix(LGModel1Pred, data[, "MyFeature00"])
----
 
----
Measure Predictive of Logistic Model
 - "Null deviance:" the response predicted with nothing but an intercept
    the lower the better
 - "Residual deviance:" the response predicted by adding another independent variable
     the lower the better
 - "AIC:" is analogous to the R-sqr of linear regression, minimum value preferred.
 - the relation between predicted and actual for a binary classification
 - is also known as sensitivity, recall, and hit-rate 
  - would be a count of the number of times 
   - predicted TRUE, and it was indeed (TP)
   - predicted FALSE, but it was TRUE (FP)
   - predicted FALSE, and it was (FN)
   - predicted TRUE , but it was FALSE (TN)
 - True Positive Rate, TPR = TP / (TP + FN)
 - True Negative Rate, TNR = TN / (TN + FP)
 - Accuracy, ratio of correct predictions to total predictions
   ACC = (TP + TN) / (TP + TN + FP + FN)

 - Simpson's paradox, when a trend appears in different groups of 
   data but disappears or reverses when the groups are combined
  - indicates some hidden variable(s) are not being taken into consideration
----

----
Multinomial logistic regression
 - when categorical variables have more than two possible values
 - uses module named 'mlogit'
 
 #load lib
 library(mlogit)
 
 #load data canned with package
 data("Heating")
 
 #this makes a variable named Heating to be in scope
 # multinomial is the "depvar" 
 # there are 4 kinds of depvar (viz gc, gr, ec, er, hp)
 # "ic" is installation cost - there is one for each kind of depvar
 # "oc" is operating cost, likewise, one for each kind of depvar
 View(Heating)
 
 #mlogit requires its own custom data frames 
 DataHeating <- mlogit.data(Heating, shape="wide", choice="depvar", varying = c(3:12))
 
 #likewise, a special version of a formula needed
 # the |0 indicates that the intercept should be omitted
 form1 <- mFormula(depvar~ic+oc|0)
 
 #get the multinomial logistic model
 MLogitModel <- mlogit(form1, DataHeating)
 
 #summary
 summary(MLogitModel)
----
 
----
Preliminary Data Cleaning
 - data is considered "neat" when
  - observations are in rows
  - variables are in columns
  - data is all in one dataset
 - in R 'NA' means not avail. and its a kind of singleton
  - it is a standin for missing values
  
 #import the data - na.strings converts all empty strings to NA
 SampleData = read.csv("CleaningData.csv", header = TRUE, na.strings=c("","NA"), sep = ";")
 
 #have a look at it 
 View(SampleData) #or "head(SampleData)" for large sets
 
 #have a look at the data frame's properties 
 str(SampleData)
 
 #for an integer incorrectly cast as a Factor
 # use format of 'as.numeric(levels(f))[f]' where "f" is the property on the frame
 # levels(SampleData$right) gets the original ints as strings
 SampleData$right <- as.integer(as.numeric(levels(SampleData$right))[SampleData$right])
 
 #to do likewise by column
 SampleData$right[SampleData$right == -19] <- NA
 
 #get the indices of NA in the data frame
 which(is.na(SampleData), arr.ind = TRUE)
 
 #gets the data frame without the NA's 
 SampleDataMinor <- na.omit(SampleData)
----

----
Detecting Outliers
 - various methods for ordered series data
 - example is Tukey's interquartile range (IQR)
  - a measure of statistical dispersion being equal to the
    difference between 75th and 25th percentiles
 
 # to quickly apply this to R data frame
 boxplot.stats(SampleDataMinor$age)
----

----
Data scaling
 - deals with problem where variables are expesses on 
   different scales (1-10 -vs- 1-1000)
 - typical two methods
  - normalization
  - standardization
  
 - Min-Max Normalization
  x_scaled = (x - x_min) / (x_max - x_min)
  
 # builtin in R 'scale'
 # x is a numeric matrix
 # center = x_min
 # scale = (x_max - x_min)
 # scale(x, center, scale)
 
 Airquality <- as.data.frame(airquality) #data part of R install
 
 #remove NA's
 Airquality<-na.omit(Airquality)
 
 #get max and min for each variable (column)
 max_data <- apply(Airquality, 2, max)
 min_data <- apply(Airquality, 2, min)
 
 #get Min-Max Normalization scaled verson of the data
 data_scaled1 <- scale(Airquality, center = min_data, scale = max_data - min_data)
 
 - Z Score Standardization
  - will rescale so that the standard normal dist is mean =1, std_dev = 1
 x_scaled = (x - mean) / std_dev
 
 # is likewise invoked with 'scale'
 mean_data <- apply(Airquality, 2, mean) 
 sd_data <- apply(Airquality, 2, sd)
 
 #get Z Score Standardization scaled version of the data
 data_scaled2 <- scale(Airquality, center = mean_data, scale = sd_data)
----

----
Data discretization
 - in R, allows for some numeric property to be replaced by a discrete range
  - e.g. break daily temp(C) into three blocks of 0-10, 11-20, 21-30
 - typical two methods
  - By Binning
  - By Histogram Analysis
  
 # 'arules' package 'discretize(x, method="interval", categories = 3, labels = NULL,    
 #                          ordered=FALSE, onlycuts=FALSE, ...)'
 # x is a numeric vector
 # method: 
 #  "interval" (eq width), 
 #  "frequency", 
 #  "cluster" (k-means clustering) 
 #  "fixed" (defer to categories)
 # categories:
 #  a number 
 #  a vector with boundaries (any outside will be labeled NA)
 # labels is names for categories
 # ordered is to return factor with ordered levels
 # onlycuts is to return computed interval boundaries
 # ... is varadic for k-means clustering
 
 #example By Binning
 library(arules)
 Nile<-as.data.frame(Nile)
 NileDiscr<-arules::discretize(Nile$x, 
                                 method = "interval", 
                                 categories = 3, 
                                 labels = c("Low", "Med", "High"), 
                                 ordered = FALSE, 
                                 onlycuts = FALSE)
 summary(NileDiscr)
 
 #example By Histogram
 # R builtin 'hist'
 # both displays on the R Plot and returns an object
 HistNile<-hist(Nile$x, breaks = 3)
---- 

----
Principal Component Analysis
 - the known technique to reduce the number of variables
    in a data set to only the principal ones
 # use R builtin 'prcomp'
 # example data at https://archive.ics.uci.edu/ml/datasets/seeds
 SeedData <- read.csv("seeds_dataset.csv", header = TRUE, sep = "")
 
 #change variable names
 names(SeedData) = c('Area', 'Perimeter', 'Compactness', 'LengthK',
                            'WidthK','AsymCoef','LengthKG','Seeds')
 #get the PCA
 PCAObj <- prcomp(SeedData[1:7)
 
 #using another plot reveals the two principal components are AsymCoef & Area
 # each variable is represented by a vector
 biplot(PCAObj, scale=0, cex=1.3)
----

----
Under and Overfitting
 - when model is only able to predict with its training data
 - most extreme case would be when there are more variables 
   than there are observations
 - underfitting is known as a bias problem
 - overfitting is known as a variance problem
 - detection happens by splitting the data between training and testing
  - data-splitting, cleave the data in two typical split is 70/30
  - k-fold, is another subdivider where data is divided into (k) random subsets
    (named folds) of roughly equal size, one is use to validate the others used
    to train, the whole process is repeated (k) times so each fold gets a chance
    as the validation set
  - Leave-one-out cross validation (LOOCV), taking everything except one 
    as training and then the one-left-out to test doing this for every observation
  
 #use the canned data "mtcars"
 data(mtcars)
 
 #partition the data into two sets
 library(caret)
 DataSplit <- createDataPartition(y = mtcars$mpg, p = 0.7, list = FALSE)
 
 #create two data sets
 TrainData <- mtcars[DataSplit,] #random select of 24 items
 TestData <- mtcars[-DataSplit,] #everything not in the 24
 
 #train function is like the lm with extra for validation
 LmFit1 <- train(mpg~., data = TrainData, method = "lm")
 
 #apply the model to the test data
 PredictedTest<-predict(LmFit1, TestData)
 
 #bind the predicted data (model) to the response variable
 ModelTest1 <- data.frame(obs = TestData$mpg, pred=PredictedTest)
 
 #examine the results
 defaultSummary(ModelTest1)
 
 #again using builtins for k-folds where k=10, "cv" means "k-folds cross validation"
 Control1 <- trainControl(method = "cv", number = 10) 
 LmFit2 <- train(mpg ~ ., data = mtcars, method = "lm", trControl = Control1, metric = "Rsquared")
 
 #again validate prediction
 PredictedTest2 <- predict(LmFit2, mtcars)
 ModelTest2 <- data.frame(obs = mtcars$mpg, pred=PredictedTest2)   
 
 #or using the Leave-one-out cross validation, 
 Control2<- trainControl(method="LOOCV")
----